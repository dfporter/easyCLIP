{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, matplotlib, pandas, collections, importlib, sys, pickle, HTSeq, random, bisect, dill\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "#os.chdir('/Users/dp/pma/dataAndScripts/clip/miseq/v2all/')\n",
    "sys.path.append('/Users/dp/pma/')\n",
    "sys.path.append('/Users/dp/pma/dataAndScripts/clip/')\n",
    "\n",
    "import sameRiver\n",
    "import sameRiver.peakFinder\n",
    "import sameRiver.peakSeqFinder\n",
    "import sameRiver.statsForCounts\n",
    "import sameRiver.rnaDataFileMaker\n",
    "import sameRiver.exp\n",
    "\n",
    "importlib.reload(sameRiver.peakFinder)\n",
    "importlib.reload(sameRiver.peakSeqFinder)\n",
    "importlib.reload(sameRiver.statsForCounts)\n",
    "importlib.reload(sameRiver.countsO)\n",
    "importlib.reload(sameRiver.rnaDataFileMaker)\n",
    "top = top_dir = '/Users/dp/pma/dataAndScripts/clip/meta/'\n",
    "os.chdir(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1\n",
    "\n",
    "# Load signal and RNA data.\n",
    "#with open('/Users/dp/pma/dataAndScripts/clip/meta/data/signal_rnas_m2.data', 'rb') as f:\n",
    "#    ssr = dill.load(f)\n",
    "importlib.reload(sameRiver.rnaDataFileMaker)\n",
    "maker = sameRiver.rnaDataFileMaker.rnaDataFileMaker()\n",
    "RNAs = maker.make_from_gtf_file(\n",
    "    gtf_filename='/Users/dp/pma/repeats_and_genome.gtf',  # New mapping method gtf.\n",
    "    #gtf_filename='/opt/genomes/repeats_and_ensembl_release94_GRCh38/combined_tsl1andNA.gtf',  # Old mapping gtf.\n",
    "    output_data_filename=f\"{top}/data/rna.data\",\n",
    ")\n",
    "exp = sameRiver.exp.exp(name='meta', file_paths=sameRiver.exp.exp.autogenerate_paths(top))\n",
    "#RNAs.example(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2\n",
    "\n",
    "# Determine the preferential binding locations for all proteins across RNAs,\n",
    "# if they exist. peakFinder.find_peaks(ssr) can use a pvals*.xlsx file\n",
    "# to limit to RNAs being bound significantly by some model. But\n",
    "# we prefer to just output everything, and can filter later.\n",
    "# This falls in the sequence ssr -> peak_locations.xlsx, and its output\n",
    "# is used by peakSignalFinder.\n",
    "\n",
    "import sameRiver.peakFinder\n",
    "import sameRiver.peakSeqFinder\n",
    "import sameRiver.peakSignalFinder\n",
    "\n",
    "importlib.reload(sameRiver.peakFinder)\n",
    "importlib.reload(sameRiver.peakSeqFinder)\n",
    "importlib.reload(sameRiver.peakSignalFinder)\n",
    "\n",
    "top_dir = top\n",
    "\n",
    "pk = sameRiver.peakFinder.peakFinder(\n",
    "    scheme_filename=f'{top}/scheme.xlsx',\n",
    "    rnas_obj=RNAs)\n",
    "\n",
    "print(\"Finding peaks...\")\n",
    "pk.find_peaks(\n",
    "    method='convolve',\n",
    "    excel_of_target_RNAs=f'{top}/tables/pvals_per_read.xlsx',\n",
    "    bedgraph_folder=f'{top}/beds/read_start/',\n",
    "    #top_n_targets=500,\n",
    "    p_cutoff=10, #only_do=['FBL'],\n",
    "    outfile=f'{top}/data/peak_locations.xlsx',\n",
    "    )\n",
    "\n",
    "print(f\"Found peaks for {len(pk.peaks.keys())} protein(s).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append('/Users/dp/pma/')\n",
    "\n",
    "import collections\n",
    "import sameRiver.peakSignalFinder\n",
    "importlib.reload(sameRiver.peakSignalFinder)\n",
    "\n",
    "# Section 3\n",
    "\n",
    "# Write an xlsx file in {top}/data for each protein in peak_locations.xlsx.\n",
    "# For each protein X in peak_locations.xlsx:\n",
    "# write a file containing signal for each bedgraph replicate file,\n",
    "# across all proteins, at the peak locations of protein X.\n",
    "# This requires ssr -> peakFinder.find_peaks(ssr) -> peak_locations.xlsx,\n",
    "# and the output files are input to statsForCountsNB to determine p values,\n",
    "# and input to peakSeqFinder for fasta files (data/seq/) of significant peak regions.\n",
    "\n",
    "#os.chdir(top_dir)\n",
    "sg = sameRiver.peakSignalFinder.peakSignalFinder(scheme_filename=f'{top}/scheme.xlsx', rnas_obj=RNAs)\n",
    "\n",
    "sg.find_signal_at_peaks(\n",
    "    excel_of_peak_locations=f'{top}/data/peak_locations.xlsx',\n",
    "    bedgraph_folder=f'{top}/beds/read_start/', #only_do=['FBL', 'SF3B1', 'PCBP1'],\n",
    "    output_folder=f'{top}/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Section 4\n",
    "\n",
    "# Evaluate p values for signal at peak locations.\n",
    "# This follows peakSignalFinder()\n",
    "# ./data/signal_at_{gene}_peak_locations.xlsx -> \n",
    "# ./data/pvals_for_signal_at_{}_peaks_per_read.xlsx\n",
    "# The output is used by peakSeqFinder.\n",
    "\n",
    "import importlib\n",
    "import sameRiver\n",
    "import sameRiver.metadata\n",
    "import sameRiver.negativeCounts\n",
    "import sameRiver.positiveCounts\n",
    "import sameRiver.scheme\n",
    "import sameRiver.statsForCountsNB\n",
    "importlib.reload(sameRiver.positiveCounts)\n",
    "importlib.reload(sameRiver.negativeCounts)\n",
    "importlib.reload(sameRiver.statsForCounts)\n",
    "importlib.reload(sameRiver.statsForCountsNB)\n",
    "importlib.reload(sameRiver.scheme)\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "def write_signal_at_peak_locations(gene, top_dir):\n",
    "    \n",
    "    counts = f'{top}/data/signal_at_{gene}_peak_locations.xlsx'\n",
    "    \n",
    "    if not os.path.exists(counts):\n",
    "        return\n",
    "    \n",
    "    positive_metadata = Namespace(\n",
    "        top_dir = top,\n",
    "        scheme_file = f'{top}/scheme.xlsx',\n",
    "        ann_counts_file = f'{top}/data/signal_at_{gene}_peak_locations.xlsx',\n",
    "        bed_file_dir = f'{top}/beds/',\n",
    "        positive_proteins = [\n",
    "            'CAPNS2', #'CCIN', \n",
    "            'CDK4', 'CHMP3',\n",
    "            'DCTN6', #'EPB41L5', \n",
    "            'ETS2', 'IDE',\n",
    "            'ITPA', 'TPGS2', 'UBA2',\n",
    "            'FBL', #'HCT116', \n",
    "            'hnRNPC',\n",
    "            'SF3B1',\n",
    "            'PCBP1', 'PCBP1:100P', 'PCBP1:100Q',\n",
    "            'PCBP1:dKH', 'CELF1',\n",
    "            'Rbfox1', 'Rbfox2', 'hnRNPD',\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    negative_metadata = Namespace(\n",
    "        top_dir = top,\n",
    "        scheme_file_with_random_proteins = f'{top}/scheme.xlsx',\n",
    "        ann_counts_file = f'{top}/data/signal_at_{gene}_peak_locations.xlsx',\n",
    "        bed_file_dir = f'{top}/beds/',\n",
    "        random_proteins = [\n",
    "            'CAPNS2', #'CCIN',\n",
    "            'CDK4', 'CHMP3',\n",
    "            'DCTN6', #'EPB41L5',\n",
    "            'ETS2', 'IDE',\n",
    "            'ITPA', 'TPGS2', 'UBA2',\n",
    "        ])\n",
    "\n",
    "    def make_negatives():\n",
    "        negatives = sameRiver.negativeCounts.negativeCounts(\n",
    "            metadata=negative_metadata, xl_rate_fname=top_dir + '/percentCrosslinked.xlsx')\n",
    "        # Optional: write_txt=True to write some txt's of the data.\n",
    "        negatives.save(fname=f'{top}/data/signal_at_{gene}_peaks_negatives.dill', write_object=True, write_txt=False)\n",
    "\n",
    "    def make_positives():\n",
    "        positives = sameRiver.positiveCounts.positiveCounts(\n",
    "            metadata=positive_metadata, xl_rate_fname=top_dir + '/percentCrosslinked.xlsx')\n",
    "        positives.save(fname=f'{top}/data/signal_at_{gene}_peaks_positives.dill', write_object=True, write_txt=False)\n",
    "        \n",
    "    # If never run before:\n",
    "    make_negatives()\n",
    "\n",
    "    # If never run before:\n",
    "    make_positives()\n",
    "\n",
    "    return True\n",
    "\n",
    "def write_pvals(gene):\n",
    "    positives = sameRiver.positiveCounts.positiveCounts.load(fname=f'{top}/data/signal_at_{gene}_peaks_positives.dill')\n",
    "    negatives = sameRiver.negativeCounts.negativeCounts.load(fname=f'{top}/data/signal_at_{gene}_peaks_negatives.dill')\n",
    "   # print(positives.raw_reads_per_gene.df)\n",
    "    print('top=', top)\n",
    "    #nb = sameRiver.statsForCountsNB.statsForCountsNB.load()\n",
    "    nb = sameRiver.statsForCountsNB.statsForCountsNB(\n",
    "        negatives=negatives, positives=positives,\n",
    "        data_dir=f'{top}/data/')\n",
    "    if nb.calculate_pvalues(which='per_read', apply_bh_adjust=True):\n",
    "        nb.write_pvals_single_file(which='per_read', outfname=f'{top}/data/pvals_for_signal_at_{gene}_peaks_per_read.xlsx')\n",
    "    if nb.calculate_pvalues(which='per_protein', apply_bh_adjust=True):\n",
    "        nb.write_pvals_single_file(which='per_protein', outfname=f'{top}/data/pvals_for_signal_at_{gene}_peaks_per_protein.xlsx')\n",
    "\n",
    "\n",
    "def combine_pvals_into_single_file(top):\n",
    "\n",
    "    _d = {}\n",
    "    for prot in set(scheme.proteins):\n",
    "        print(prot)\n",
    "        fname = f'{top}/data/pvals_for_signal_at_{prot}_peaks_per_read.xlsx'\n",
    "        if not os.path.exists(fname):\n",
    "            continue\n",
    "        df = pandas.read_excel(fname, index_col=0)\n",
    "        if prot in df:\n",
    "            _d[prot] = dict(zip(df.index, df[prot]))\n",
    "        else:\n",
    "            print(f\"Did not find {prot} in {fname}\")\n",
    "    \n",
    "    df = pandas.DataFrame(_d)\n",
    "    df['gene_name'] = df.index\n",
    "    df.fillna(1., inplace=True)\n",
    "    \n",
    "    print('====')\n",
    "    print(df.head())\n",
    "    df.to_excel(f'{top}/tables/pvals_at_peaks_per_read.xlsx')\n",
    "\n",
    "    _d = {}\n",
    "    for prot in [_ for _ in scheme.proteins if _ in df]:\n",
    "        fname = f'{top}/data/pvals_for_signal_at_{prot}_peaks_per_protein.xlsx'\n",
    "        \n",
    "        if not os.path.exists(fname):\n",
    "            continue\n",
    "        \n",
    "        df = pandas.read_excel(fname, index_col=0)\n",
    "        _d[prot] = dict(zip(df.index, df[prot]))\n",
    "        \n",
    "    df = pandas.DataFrame(_d)\n",
    "    df.fillna(1., inplace=True)\n",
    "    df['gene_name'] = df.index\n",
    "\n",
    "    print(df.head(1))\n",
    "    df.to_excel(f'{top}/tables/pvals_at_peaks_per_protein.xlsx')\n",
    "\n",
    "    \n",
    "scheme = sameRiver.scheme.scheme(f'{top}/scheme.xlsx')\n",
    "\n",
    "print('----')\n",
    "\n",
    "for prot in list(scheme.proteins):\n",
    "    if write_signal_at_peak_locations(prot, top_dir):\n",
    "        write_pvals(prot)\n",
    "    else:\n",
    "        print(f'failed for {prot}')\n",
    "        \n",
    "combine_pvals_into_single_file(top)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homer_command = \"\"\"\n",
    "# For some reason, homer1 works while homer2 doesn't.\n",
    "\n",
    "export PATH=$PATH:/Users/dfporter/homer/bin/\n",
    "\n",
    "./bin/findMotifs.pl ../pma/tables/seqs/hnRNPC.fa  fasta ./hnRNPC -fasta ../pma/tables/seqs/randoms_for_hnRNPC.fa -rna -homer1 \n",
    "./bin/findMotifs.pl ../pma/tables/seqs/FBL.fa  fasta ./FBL -fasta ../pma/tables/seqs/randoms_for_FBL.fa  -rna -homer1\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble outputs (made in write_fasta_for_homer.ipynb) into one file.\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "os.system('export PATH=$PATH:/Users/dp/homer/bin/')\n",
    "print('export PATH=$PATH:/Users/dp/homer/bin/')\n",
    "for fname in glob.glob(top_dir+'/data/seqs/*fa'):\n",
    "    if 'random' in fname:\n",
    "        continue\n",
    "\n",
    "    gene = os.path.basename(fname).split('.fa')[0]\n",
    "    random_fname = os.path.dirname(fname) + '/randoms_for_{0}.fa'.format(gene)\n",
    "    homer = '/Users/dfporter/homer/bin/findMotifs_edit.pl'\n",
    "    cmd = \"{} {} fastq ./{} -fasta {} -rna -homer1\".format(homer, fname, gene, random_fname)\n",
    "    #print(cmd)\n",
    "    #os.system(cmd)\n",
    "    \n",
    "class logoAssembly:\n",
    "    \n",
    "    def __init__(self, homer_dir='./'):\n",
    "        self.homer_dir = homer_dir\n",
    "    \n",
    "    def find_all_svg_motif1_logos(self):\n",
    "        print(f'{self.homer_dir}/*/motif1.logo.svg')\n",
    "        svgs_motif1, svgs_motif2 = {}, {}\n",
    "        for path in glob.glob(f'{self.homer_dir}/*/*/motif1.logo.svg'):\n",
    "            with open(path) as f:\n",
    "                svgs_motif1[os.path.dirname(path)] = f.readlines()\n",
    "                \n",
    "        for path in glob.glob(f'{self.homer_dir}/*/*/motif2.logo.svg'):\n",
    "            print(path)\n",
    "            with open(path) as f:\n",
    "                svgs_motif2[os.path.dirname(path)] = f.readlines()\n",
    "        #print(svgs)\n",
    "        \n",
    "        header = \"\"\"<HTML><HEAD><TITLE>Homer de novo Motif Results</TITLE></HEAD>\n",
    "<BODY>\n",
    "<H1>Homer <i>de novo</i> Motif Results </H1>\n",
    "\"\"\"\n",
    "        print(os.getcwd())\n",
    "        comb = open(self.homer_dir+'/all_logos.html', 'w')\n",
    "        comb.write(header)\n",
    "        for path, lines in svgs_motif1.items():\n",
    "            \n",
    "            comb.write('<H2>{}</H2>\\n'.format(os.path.dirname(path)))\n",
    "            comb.write(''.join(lines))\n",
    "            if path in svgs_motif2:\n",
    "                comb.write(''.join(svgs_motif2[path]))                \n",
    "        comb.close()\n",
    "        \n",
    "logos = logoAssembly(\n",
    "    homer_dir='/Users/dp/homer/top10Ktargets_5_min_height_no_Pvalue_cutoffs_20k_controlSeqs_mRNA_only_old_mapping_eg_repeats_first_Thursday'\n",
    ")\n",
    "logos.find_all_svg_motif1_logos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
