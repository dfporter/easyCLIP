{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts using counts.txt.\n",
    "\n",
    "Generally, the raw sequencing is first processed with a script like this:\n",
    "```python\n",
    "import sameRiver\n",
    "import sameRiver.mapping\n",
    "import sameRiver.exp\n",
    "import sameRiver.metaExp\n",
    "import importlib\n",
    "import sameRiver.rnaDataFileMaker\n",
    "from used_seq_runs import used_sequencing_runs\n",
    "\n",
    "def get_RNAs():\n",
    "    # Make data/rna.data file to assign reads to genes.\n",
    "    maker = sameRiver.rnaDataFileMaker.rnaDataFileMaker()\n",
    "    RNAs = maker.make_from_gtf_file(gtf_filename='repeats_and_genome.gtf')\n",
    "    return RNAs\n",
    "\n",
    "meta = sameRiver.metaExp.metaExp(file_paths={'top_dir': 'meta/'})\n",
    "\n",
    "for name, paths in used_sequencing_runs.items():\n",
    "    meta.add_exp(\n",
    "        sameRiver.exp.exp(\n",
    "            name=name,\n",
    "            file_paths=sameRiver.exp.exp.autogenerate_paths(paths['location'])\n",
    "        ))\n",
    "\n",
    "RNAs = get_RNAs()\n",
    "\n",
    "def counts(ex):\n",
    "    #####\n",
    "    # Make counts file.\n",
    "    # Outputs a data/bed_x.data file that holds signal, w/o RNA information:\n",
    "    ex.make_signal_data_file()\n",
    "    # Assigns signal to genes and writes counts.txt:\n",
    "    ex.make_scheme_signal_RNA_data_files(\n",
    "        rna_data_object=RNAs)\n",
    "    # Make ann_counts.txt file. This has simplified\n",
    "    # column names and biotypes.\n",
    "    ex.annotate_counts_file()\n",
    "\n",
    "def process(exp):\n",
    "    exp.read_scheme()\n",
    "    exp.split_by_barcode()\n",
    "    exp.convert_split_r1r2_folder_to_long_filenames()\n",
    "    exp.preprocess_split_barcodes_folder()\n",
    "    exp.mapping(clobber=True)\n",
    "    exp.determine_statistics()\n",
    "    counts(exp)\n",
    "\n",
    "[process(meta.exps[exp_name]) for exp_name in meta.exps]\n",
    "\n",
    "meta.combine_scheme_files()\n",
    "meta.combine_scheme_stat_files()\n",
    "meta.combine_counts_files()\n",
    "meta.combine_wig_files()\n",
    "meta.annotate_counts_file()\n",
    "```\n",
    "\n",
    "This outputs counts.txt. The raw signal information is in beds/read_start/ bedgraph files.\n",
    "This analysis.ipynb script concerns processing that only needs these inputs, and outputs further processed information\n",
    "used by more specific notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code demonstrates the re-creation of counts.txt files from bedgraphs.\n",
    "\n",
    "```python\n",
    "import os, sys, re, glob, pandas, importlib\n",
    "sys.path.append('/Users/dp/pma/')\n",
    "import sameRiver\n",
    "import sameRiver.exp\n",
    "import sameRiver.rnaDataFileMaker\n",
    "\n",
    "importlib.reload(sameRiver.exp)\n",
    "importlib.reload(sameRiver.rnaDataFileMaker)\n",
    "\n",
    "top_dir = '/Users/dp/pma/dataAndScripts/clip/old_mapping_meta/'\n",
    "\n",
    "ex = sameRiver.exp.exp(\n",
    "    name='00', file_paths=sameRiver.exp.exp.autogenerate_paths(top_dir))\n",
    "\n",
    "ex.read_scheme()\n",
    "\n",
    "maker = sameRiver.rnaDataFileMaker.rnaDataFileMaker()\n",
    "RNAs = maker.make_from_gtf_file(gtf_filename='/Users/dp/pma/repeats_and_genome.gtf')\n",
    "\n",
    "\n",
    "ex.make_signal_data_file(clobber=True)\n",
    "\n",
    "# Assigns signal to genes and writes counts.txt:\n",
    "ex.make_scheme_signal_RNA_data_files(rna_data_object=RNAs)\n",
    "ex.annotate_counts_file()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move blacklisted datasets (repeats, empty, contaminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "black_list = [\n",
    "                'Exp61_HCT116_GTAGCC_TCA',  # <1,000 reads\n",
    "                'Exp61_HCT116_GTAGCC_AGT',  # <10,000 reads\n",
    "                'Exp15_AURKA_TCTGAG_TCA',  # <10,000 reads\n",
    "\n",
    "                'Exp16_FBL_AGCTAG_CAG',  # Very small dataset.\n",
    "                'Exp16_hnRNPC_TGAGTG_AGT',\n",
    "                'Exp16_hnRNPC_TGAGTG_CAG',\n",
    "                'Exp28_hnRNPC_CGATTA_AAC',\n",
    "                'Exp31_UBA2_TGAGTG_AAC',# Too correlated with CDK4 AAC Exp31.\n",
    "                'Exp31_UBA2_TGAGTG_CAG', # Empty.\n",
    "                'Exp31_UBA2_TGAGTG_CAG',\n",
    "                'Exp31_CDK4_GCCATG_AAC', # Too correlated with UBA2 AAC Exp31.\n",
    "                'Exp31_CDK4_GCCATG_CAG', # Empty.\n",
    "                'Exp33_CDK4_GCCATG_AGT',\n",
    "                'Exp31_CDK4_GCCATG_CAG',\n",
    "                'Exp33_CAPNS6_CACTGT_TCA', # Empty.\n",
    "                'Exp61_PCBP1-100P_GCCATG_TCA',  # Miseq run replaced by Hiseq (hp).\n",
    "                'Exp61_PCBP1-100P_GCCATG_AGT',  # Miseq run replaced by Hiseq (hp).\n",
    "                'Exp61_PCBP1-100Q_AGCTAG_TCA',  # Miseq run replaced by Hiseq (hp).\n",
    "                'Exp61_PCBP1-100Q_AGCTAG_AGT',  # Miseq run replaced by Hiseq (hp).\n",
    "                'Exp61_PCBP1-dKH_ATCGTG_TCA',  # Miseq run replaced by Hiseq (hp).\n",
    "                'Exp61_PCBP1-dKH_ATCGTG_AGT',  # Miseq run replaced by Hiseq (hp).\n",
    "                'Exp61_PCBP1_CGATTA_AGT',  # Miseq run replaced by Hiseq (hp).\n",
    "                'Exp61_PCBP1_CGATTA_TCA',  # Miseq run replaced by Hiseq (hp).\n",
    "                'YBX',\n",
    "                'AURKA'\n",
    "]\n",
    "import glob\n",
    "\n",
    "# Move blacklisted begraphs to another folder, then make a file of total read counts.\n",
    "top_dir = top = '/Users/dp/pma/dataAndScripts/clip/meta//'\n",
    "\n",
    "for name in black_list:\n",
    "    blacklist_dir = f\"{top}/beds/blacklisted_read_start/\"\n",
    "    os.makedirs(blacklist_dir, exist_ok=True)\n",
    "    for fname in glob.glob(f\"{top}/beds/read_start/*{name}*wig\"):\n",
    "        cmd = f\"mv {fname} {blacklist_dir}/\"\n",
    "        print(cmd)\n",
    "        os.system(cmd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the total read numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sameRiver.total_read_numbers import total_read_numbers\n",
    "total_read_numbers(folder=f'{top}/beds/read_start/', outfile=f\"{top}/data/total_read_numbers.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read a counts.txt file and get biotypes, reads per million, and XLs per protein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = top = '/Users/dp/pma/dataAndScripts/clip/meta/'\n",
    "os.chdir(top_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, glob, pandas, importlib, dill\n",
    "import numpy as np\n",
    "sys.path.append('/Users/dp/pma/')\n",
    "import sameRiver\n",
    "import sameRiver.exp\n",
    "import sameRiver.rnaDataFileMaker\n",
    "import sameRiver.readsPerGene\n",
    "importlib.reload(sameRiver.readsPerGene)\n",
    "from sameRiver.readsPerGene import *\n",
    "\n",
    "\n",
    "rpg = rawReadsPerGene(f'{top_dir}/counts.txt', scheme_filename=f'{top_dir}/scheme.xlsx')\n",
    "rpg.add_biotypes_column(\n",
    "#    gtf_filename='/Users/dp/pma/repeats_and_genome.gtf'\n",
    "    gtf_filename='/opt/genomes/repeats_and_ensembl_release94_GRCh38/combined_tsl1andNA.gtf'\n",
    ")\n",
    "rpg.df.to_csv(f'{top_dir}/ann_counts.txt', sep='\\t')\n",
    "\n",
    "rpm = readsPerMillion(rpg, load_total_read_numbers=f\"{top}/data/total_read_numbers.txt\")\n",
    "xpp = xlsPerProtein(rpm, xl_rate_fname='/Users/dp/pma/percentCrosslinked.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write File 3.\n",
    "\n",
    "import xlsxwriter\n",
    "writer = pandas.ExcelWriter(f'{top}/tables/Table 3 Counts per RNA raw, per read or per protein.xlsx', engine='xlsxwriter')\n",
    "\n",
    "def order_columns(df):\n",
    "    df['Gene name'] = df.index\n",
    "    def sorting(_list):\n",
    "         return sorted(_list, key=lambda x: x.split('_')[1] if ('_' in x) else x)[::-1]\n",
    "\n",
    "    cols = ['Gene name', 'Gene type'] + sorting([x for x in df.columns if x not in ['Gene type', 'Gene name']])\n",
    "    df = df.loc[:, cols]\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "df = order_columns(rpg.df)\n",
    "df.to_excel(writer, sheet_name='Raw counts', index=False)\n",
    "\n",
    "df = order_columns(rpm.df)\n",
    "df.to_excel(writer, sheet_name='Per million reads', index=False)\n",
    "\n",
    "df = order_columns(xpp.df)\n",
    "df.to_excel(writer, sheet_name='Per 1E10 proteins', index=False)\n",
    "\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write File 4\n",
    "\n",
    "import xlsxwriter\n",
    "writer = pandas.ExcelWriter(f'{top}/tables/Table 4 Significance values.xlsx', engine='xlsxwriter')\n",
    "\n",
    "pvals = pandas.read_excel(f'{top}/tables/pvals_per_read.xlsx', index_col=0)\n",
    "pvals = order_columns(pvals)#.head()\n",
    "#pvals['Gene name'] = pvals.index\n",
    "pvals.to_excel(writer, sheet_name='Per million reads', index=False)\n",
    "\n",
    "pvals = pandas.read_excel(f'{top}/tables/pvals_per_protein.xlsx', index_col=0)\n",
    "pvals = order_columns(pvals)#.head()\n",
    "#pvals['Gene name'] = pvals.index\n",
    "pvals.to_excel(writer, sheet_name='Per protein', index=False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pandas.ExcelWriter(f'{top}/tables/Table 5 Peak locations.xlsx', engine='xlsxwriter')\n",
    "\n",
    "locs = pandas.read_excel(f\"{top}/data/peak_locations.xlsx\", index_col=0)\n",
    "locs = order_columns(locs)\n",
    "print(locs.head())\n",
    "\n",
    "locs.to_excel(writer, sheet_name='Peak locations', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pandas.ExcelWriter(f'{top}/tables/Table 6 DESeq2 of mutation effects in CLIP.xlsx', engine='xlsxwriter')\n",
    "#writer = xlsxwriter.workbook.Workbook(f'{top}/tables/File 6 DESeq2 of mutation effects in CLIP.xlsx')\n",
    "\n",
    "rename = {\n",
    "    'Name': 'RNA',\n",
    "    'logFC': 'DESeq2 log2 fold change MUT/WT',\n",
    "    'logCPM': 'DESeq2 log2 counts per million over all libraries',\n",
    "    'F': 'DEseq2 F-statistics',\n",
    "    'PValue': 'Pvalue',\n",
    "    '-log10(FDR)': '-log10(P value)'\n",
    "}\n",
    "\n",
    "for dataset in [\n",
    "    'A1CF_vs_A1CF-E34K_DESeq2', 'FUBP1_vs_FUBP1-R429C_DESeq2',\n",
    "    'KHDRBS2_vs_KHDRBS2-R168C_DESeq2', 'PCBP1_hp_vs_PCBP1-100Q_DESeq2']:\n",
    "    fname = f\"{top}/tables/{dataset}.xlsx\"\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    df = pandas.read_excel(fname, index_col=0)\n",
    "    df.columns = [rename.get(x, x) for x in df.columns]\n",
    "    print(df.head())\n",
    "    \n",
    "    dataset = re.sub('_hp', '', dataset)\n",
    "    dataset = re.sub('_DESeq2', '', dataset)\n",
    "    \n",
    "    df.to_excel(writer, sheet_name=dataset, index=False)\n",
    "\n",
    "    worksheet = writer.sheets[dataset]\n",
    "    worksheet.set_column('A:G', 20)\n",
    "    \n",
    "   # break\n",
    "    \n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sameRiver.metadata.negative_metadata as negative_metadata\n",
    "\n",
    "rpg = rawReadsPerGene(f'{top_dir}/ann_counts.txt', scheme_filename=f'{top_dir}/scheme.xlsx')\n",
    "#rpg.add_biotypes_column(\n",
    "#    gtf_filename='/Users/dp/pma/repeats_and_genome.gtf'\n",
    "#    gtf_filename='/opt/genomes/repeats_and_ensembl_release94_GRCh38/combined_tsl1andNA.gtf'\n",
    "#)\n",
    "#rpg.df.to_csv(f'{top_dir}/ann_counts.txt', sep='\\t')\n",
    "\n",
    "rpm = readsPerMillion(rpg)\n",
    "\n",
    "a = rpg.df.sum()\n",
    "\n",
    "xpp = xlsPerProtein(rpm, xl_rate_fname='/Users/dp/pma/percentCrosslinked.xlsx')\n",
    "\n",
    "def as_fold_change(df):\n",
    "    negatives = df.loc[:, [x for x in df.columns if any([r in x for r in negative_metadata.random_proteins])]]\n",
    "    negative_sum = negatives.mean(axis=1)\n",
    "    \n",
    "    df = df.head()\n",
    "\n",
    "    get_numeric_columns = lambda _df: [x for x in _df.columns if (_df[x].dtype.kind in 'bifc')]\n",
    "    df = df[get_numeric_columns(df)].copy()\n",
    "\n",
    "    return df.apply(lambda x: x/negative_sum[x.name], axis=1)\n",
    "\n",
    "import scipy.stats as stats\n",
    "def ttest(readsPerObj):\n",
    "    df = readsPerObj.df\n",
    "    negatives = df.loc[:, [x for x in df.columns if any([r in x for r in negative_metadata.random_proteins])]]\n",
    "    #print(negatives)\n",
    "    #df = df.head(1000)\n",
    "    \n",
    "    df = df[readsPerObj.numeric_columns(df)].copy()    \n",
    "    \n",
    "    proteins = readsPerObj.proteins()\n",
    "    \n",
    "    lookup = {protein: readsPerObj.columns_for_a_protein(protein) for protein in ['hnRNPC']}\n",
    "    \n",
    "    def ttesty(x):\n",
    "        neg_vals = negatives.loc[x.name].values\n",
    "        _d = {}\n",
    "        for protein, cols in lookup.items():\n",
    "            tval = stats.ttest_ind(neg_vals, x[cols].values)\n",
    "            _d[protein] = tval.pvalue\n",
    "        return _d#pandas.Series(_d)\n",
    "    \n",
    "    t = df.apply(lambda s: ttesty(s), axis=1)\n",
    "    print(t)\n",
    "    return t\n",
    "\n",
    "print('ttest:')\n",
    "fold = ttest(rpm)\n",
    "print(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold['_ambiguous']['hnRNPC']\n",
    "#df = original['user'].apply(pd.Series)\n",
    "q = pandas.DataFrame(fold.values.tolist(), index=fold.index)\n",
    "q.to_excel(f'{top}/tables/pvals_by_ttest.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform statistics on the counts file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, glob, pandas, importlib, dill\n",
    "sys.path.append('/Users/dp/pma/')\n",
    "\n",
    "import sameRiver.metadata.negative_metadata as negative_metadata\n",
    "import sameRiver.metadata.positive_metadata_all# as positive_metadata\n",
    "importlib.reload(sameRiver.metadata.positive_metadata_all)\n",
    "import sameRiver.negativeCounts\n",
    "import sameRiver.positiveCounts\n",
    "import sameRiver.scheme\n",
    "import sameRiver.statsForCountsNB\n",
    "importlib.reload(sameRiver.positiveCounts)\n",
    "importlib.reload(sameRiver.negativeCounts)\n",
    "importlib.reload(sameRiver.statsForCountsNB)\n",
    "importlib.reload(sameRiver.scheme)\n",
    "\n",
    "positive_metadata = sameRiver.metadata.positive_metadata_all\n",
    "\n",
    "# Reset these paths.\n",
    "positive_metadata.top_dir = top_dir\n",
    "positive_metadata.scheme_file = top_dir + '/scheme.xlsx'\n",
    "positive_metadata.ann_counts_file = top_dir + '/ann_counts.txt'\n",
    "positive_metadata.bed_file_dir = top_dir + '/beds/'\n",
    "#positive_metadata.positive_proteins = ['hnRNPC']\n",
    "print('positives;', positive_metadata.positive_proteins)\n",
    "negative_metadata.top_dir = top_dir\n",
    "negative_metadata.scheme_file_with_random_proteins = top_dir + '/scheme.xlsx'\n",
    "negative_metadata.ann_counts_file = top_dir + '/ann_counts.txt'\n",
    "negative_metadata.bed_file_dir = top_dir + '/beds/'\n",
    "\n",
    "print('....', negative_metadata.top_dir)\n",
    "# If never run before:\n",
    "negatives = sameRiver.negativeCounts.negativeCounts(negative_metadata, xl_rate_fname='/Users/dp/pma/percentCrosslinked.xlsx')\n",
    "print('>>>>', negatives.metadata.data_folder)\n",
    "# Optional: write_txt=True to write some txt's of the data.\n",
    "negatives.save(write_object=True, write_txt=True)\n",
    "#print(negatives.lowest_positive_vals)\n",
    "\n",
    "# If never run before:\n",
    "positives = sameRiver.positiveCounts.positiveCounts(positive_metadata, xl_rate_fname='/Users/dp/pma/percentCrosslinked.xlsx')\n",
    "positives.save(write_object=True, write_txt=True)\n",
    "\n",
    "# If loading:\n",
    "#positives = sameRiver.positiveCounts.positiveCounts.load(fname='/Users/dp/pma/dataAndScripts/clip/meta/data/positives_countsO.dill')\n",
    "#str(negatives.lowest_positive_vals['per_read'])[:2000]#['PLEKHN1::exon']\n",
    "nb = sameRiver.statsForCountsNB.statsForCountsNB(\n",
    "    negatives=negatives, positives=positives, data_dir=positive_metadata.top_dir + '/data/')\n",
    "\n",
    "# Write per read pvalues. Masked: if absolute read #/gene below a cutoff, set p value to 1.\n",
    "nb.calculate_pvalues(which='per_read', test_mode=False)\n",
    "nb.write_pvals_single_file(which='per_read', outfname=f'{top}/tables/pvals_per_read_unmasked.xlsx')\n",
    "nb.mask_low_absolute_counts(which='per_read')\n",
    "nb.write_pvals_single_file(which='per_read', outfname=f'{top}/tables/pvals_per_read.xlsx')\n",
    "\n",
    "# Write per protein pvalues. Masked: if absolute read #/gene below a cutoff, set p value to 1.\n",
    "nb.calculate_pvalues(which='per_protein')\n",
    "nb.write_pvals_single_file(which='per_protein', outfname=f'{top}/tables/pvals_per_protein_unmasked.xlsx')\n",
    "nb.mask_low_absolute_counts(which='per_read')\n",
    "nb.write_pvals_single_file(which='per_protein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "sys.path.append('/Users/dp/pma/')  # Wherever sameRiver is put.\n",
    "import sameRiver\n",
    "import sameRiver.mapping\n",
    "importlib.reload(sameRiver.mapping)\n",
    "\n",
    "# Get some utilities.\n",
    "g = sameRiver.mapping.repeatsGenome()\n",
    "\n",
    "# If needed:\n",
    "import sameRiver.gtf\n",
    "#sameRiver.gtf.subset_to_only_tsl1_and_NA('gencode.v29.primary_assembly.annotation.gtf')\n",
    "# Outputs gencode.v29.primary_assembly.annotation.gtf.exons_only_tsl1andNA\n",
    "\n",
    "g.igv_version_of_gtf(\n",
    "    gtf_filename='/opt/genomes/repeats_and_ensembl_release94_GRCh38/combined_tsl1andNA.gtf',\n",
    "    out_gtf_fname='/opt/genomes/repeats_and_ensembl_release94_GRCh38/igv_labelling_combined_tsl1andNA.gtf')\n",
    "\n",
    "g.setup_genomes(\n",
    "    repeats_fasta_directory='/Users/dp/pma/dataAndScripts/clip/RepEnrich2/hg38re/',\n",
    "    genomic_gtf='/opt/genomes/gencode.v29/gencode.v29.primary_assembly.annotation.gtf.exons_only_tsl1andNA',\n",
    "    igv_output_directory='/Users/dp/pma/dataAndScripts/clip/RepEnrich2/for_igv/',\n",
    "    repeats_gtf='/opt/genomes/temp/repeats_as_separate_chroms.gtf',\n",
    "    combined_gtf='/opt/genomes/temp/repeats_and_genome.gtf',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_proteins = [\n",
    "    'CAPNS2',\n",
    "    #'CCIN', # Dataset too small.\n",
    "    'CDK4', 'CHMP3',\n",
    "    'DCTN6',\n",
    "    'EPB41L5',  # Dataset too small.\n",
    "    'ETS2', 'IDE',\n",
    "    'ITPA', 'TPGS2', \n",
    "    'UBA2',\n",
    "    #'HCT116',\n",
    "    ]\n",
    "\n",
    "negatives = sameRiver.negativeCounts.negativeCounts(negative_metadata, xl_rate_fname='/Users/dp/pma/percentCrosslinked.xlsx')\n",
    "positives = sameRiver.positiveCounts.positiveCounts(positive_metadata, xl_rate_fname='/Users/dp/pma/percentCrosslinked.xlsx')\n",
    "df = positives.reads_per_million.df.copy()\n",
    "\n",
    "df = df.loc[:, [not any([x in col for x in random_proteins]) for col in df]]\n",
    "df = df.loc[:, [df[col].dtype.kind in 'bifc' for col in df.columns]]\n",
    "#print(df.sort_index(by='Exp92_ETS2_CGAAAC_AGT', ascending=False))\n",
    "df = df.loc[[x for x in df.index if x not in ['_no_feature', '_ambiguous', 'LSU-rRNA_Hsa::exon', 'SSU-rRNA_Hsa::exon']], :]\n",
    "\n",
    "_mean = df.mean(axis=1).to_numpy()\n",
    "print(np.min(_mean))\n",
    "for col in df:\n",
    "    df[col] = [(x-m)/m for x,m in zip(df[col], _mean)]\n",
    "#df = df.apply(np.abs)\n",
    "df = df.apply(np.log2)\n",
    "for col in df:\n",
    "    plt.scatter(x=np.log10(_mean), y=df[col], alpha=0.01)\n",
    "plt.xlim(0, 4)\n",
    "plt.ylim(-7, 7)\n",
    "plt.show()\n",
    "plt.clf(); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_proteins = [\n",
    "    'FBL', \n",
    "    'hnRNPC',\n",
    "    'SF3B1',\n",
    "    'PCBP1', #'PCBP1-100P', 'PCBP1-100Q', 'PCBP1-dKH',\n",
    "    'CELF1', 'Rbfox1', 'Rbfox2', 'hnRNPD',\n",
    "    'A1CF', #'A1CF-E34K',\n",
    "    #'BARD1', 'BRCA1',\n",
    "    'CRNKL1', #'CRNKL1-S128F',\n",
    "    #'DDX3X', 'DDX3X-R528C',\n",
    "    'FUBP1', #'FUBP1-R429C',\n",
    "    'KHDRBS2', #'KHDRBS2-R168C',\n",
    "    #'RARS2', 'RARS2-R6C',\n",
    "    #'RPL5', 'RPL5-E82K',\n",
    "    #'SMAD3',\n",
    "    #'SMAD4', 'SMAD4-R361H',\n",
    "    #'PCBP1', 'PCBP1:100P', 'PCBP1:100Q',\n",
    "    #'PCBP1:dKH',\n",
    "]\n",
    "random_proteins = [\n",
    "    'CAPNS2',\n",
    "    #'CCIN', # Dataset too small.\n",
    "    'CDK4', 'CHMP3',\n",
    "    'DCTN6',\n",
    "    'EPB41L5',  # Dataset too small.\n",
    "    'ETS2', 'IDE',\n",
    "    'ITPA', 'TPGS2', 'UBA2',\n",
    "    'HCT116',\n",
    "    ]\n",
    "def pos(_df):\n",
    "    return _df.loc[:,[c for c in _df.columns if any([x in c for x in positive_proteins])]]\n",
    "\n",
    "negatives = sameRiver.negativeCounts.negativeCounts(negative_metadata, xl_rate_fname='/Users/dp/pma/percentCrosslinked.xlsx')\n",
    "positives = sameRiver.positiveCounts.positiveCounts(positive_metadata, xl_rate_fname='/Users/dp/pma/percentCrosslinked.xlsx')\n",
    "\n",
    "def CV_low(arr):\n",
    "    #if arr.dtype.kind not in 'bifc':\n",
    "    #    return ''\n",
    "    arr = np.array(arr)\n",
    "    return np.min(arr)#stats.norm.interval(0.95, loc=np.mean(arr), scale=np.std(arr))\n",
    "df = negatives.reads_per_million.df.copy()\n",
    "neg_min = df.loc[:, [df[col].dtype.kind in 'bifc' for col in df.columns]].apply(np.min, axis=1)\n",
    "neg_max = df.loc[:, [df[col].dtype.kind in 'bifc' for col in df.columns]].apply(np.max, axis=1)\n",
    "\n",
    "df['_sum'] = df.mean(axis=1).tolist()\n",
    "#print(df.head())\n",
    "df = df.loc[:,['_sum']]\n",
    "to_negative_sum = dict(zip(df.index, df._sum))\n",
    "to_neg_min = dict(zip(df.index, neg_min))\n",
    "to_neg_max = dict(zip(df.index, neg_max))\n",
    "positives.reads_per_million.df['negatives'] = [to_negative_sum.get(x, 0) for x in positives.reads_per_million.df.index]\n",
    "positives.reads_per_million.df['neg_min'] = [to_neg_min.get(x, 0) for x in positives.reads_per_million.df.index]\n",
    "positives.reads_per_million.df['neg_max'] = [to_neg_max.get(x, 0) for x in positives.reads_per_million.df.index]\n",
    "#print(a)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def formed(series):\n",
    "    if series.dtype.kind not in 'bifc':\n",
    "        return False\n",
    "    a = np.log10(series[series>0])\n",
    "    if len(a) < 10:\n",
    "        return False\n",
    "    return a\n",
    "\n",
    "def histy(df, no_unknown=False, no_neg=False):\n",
    "    plt.clf(); plt.close()\n",
    "    plotted = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        alpha, color, lw = 0.2, 'k', 1.\n",
    "        \n",
    "        is_pos = any([x in col for x in positive_proteins])\n",
    "        is_neg = any([x in col for x in random_proteins])\n",
    "\n",
    "        if no_neg and is_neg:\n",
    "            continue\n",
    "            \n",
    "        if is_pos:\n",
    "            color = 'r'\n",
    "        elif is_neg:\n",
    "            color = 'k'\n",
    "        elif col in ['negatives']:\n",
    "            color = 'g'\n",
    "            alpha=1.\n",
    "            lw = 2\n",
    "        elif no_unknown:\n",
    "            continue\n",
    "        else:\n",
    "            color = 'b'\n",
    "    \n",
    "        if type(a := formed(df[col])) != type(True):\n",
    "            density = stats.gaussian_kde(a)\n",
    "            #plt.hist(a, bins=20, alpha=0.2, color=color, histtype='step')\n",
    "            x = np.linspace(-0.1, 4)\n",
    "            plt.plot(x, density(x), color=color, alpha=alpha, lw=lw)\n",
    "            plotted.append(col)\n",
    "#        plt.xlim(-0.1, 4)\n",
    "    plt.show()\n",
    "    plt.clf(); plt.close()\n",
    "    print(f\"Plotted: {plotted}\")\n",
    "histy(df)\n",
    "histy(positives.raw_reads_per_gene.df, no_unknown=True)\n",
    "histy(positives.reads_per_million.df, no_unknown=True, no_neg=True)\n",
    "histy(positives.reads_per_protein.df, no_unknown=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit a stats_in_scheme.xlsx file to clean up some columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, re, glob, pandas, importlib, dill\n",
    "import numpy as np\n",
    "sys.path.append('/Users/dp/pma/')\n",
    "sys.path.append('/Users/dp/pma/RBP missense mutations/')\n",
    "#import sameRiver\n",
    "import xlLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "known_rbps = [\n",
    "    'U2AF1', \n",
    "    #'DDX3X', \n",
    "    'NOVA1', 'DDX50', 'RBM39', \n",
    "    'YTHDC2', \n",
    "    'SF3B1',  'NUFIP', 'PCBP1', \n",
    "    'SRSF2', 'RBM11', 'DICER1', 'RBFOX1',\n",
    "    'hnRNP C', 'FBL', 'eIF4H', 'CELF1', 'hnRNP D', 'STAU1',\n",
    "    'DHX21', 'NSUN2', 'RBFOX2',\n",
    "    \n",
    "    'RPL5', 'RPL5-E82K', 'RPL5 E82K',\n",
    "    'KHDRBS2', 'KHDRBS2-R168C', 'KHDRBS2 R168C',\n",
    "    'A1CF', 'A1CF-E34K', 'A1CF E34K',\n",
    "#    'RARS2', 'RARS2-R6C',\n",
    "    'FUBP1', 'FUBP1-R429C', 'FUBP1 R429C',\n",
    "]\n",
    "known_rbps.extend([x.upper() for x in known_rbps])\n",
    "known_rbps.extend([x.replace(' ', '').upper() for x in known_rbps])\n",
    "\n",
    "putative = [\n",
    "    'SMAD3', 'SMAD4', 'BRCA1', 'BARD1',\n",
    "    'CNOT9', 'HNRNPCL1', 'CNOT1', 'EIF1AX',\n",
    "    'PABPC4L',    \n",
    "    'DCP1B', 'BCLAF1',\n",
    "    'CRNKL1', 'CRNKL1-S128F',\n",
    "    'SMAD4', 'SMAD4-R361H',\n",
    "    \n",
    "    #'RPL5',\n",
    "]\n",
    "\n",
    "non_rbp = [\n",
    "    'CAPNS2','CCIN',\n",
    "    'CDK4','CHMP3','DCTN6','EGFP',\n",
    "    'EPB41L5',\n",
    "    'ETS2','IDE','ITPA','TPGS2','UBA2'\n",
    "]\n",
    "\n",
    "incertae_sedis = [\n",
    "    'TDRKH', 'EEF1B2', \n",
    "    'RARS2', 'RARS2-R6C', 'RARS2 R6C']\n",
    "\n",
    "def categorize(protein):\n",
    "    if protein in known_rbps:\n",
    "        return 'RBP'\n",
    "    elif protein in putative:\n",
    "        return 'Putative'\n",
    "    elif protein in non_rbp:\n",
    "        return 'non-RBP'\n",
    "    elif protein in incertae_sedis:\n",
    "        return 'Incertae sedis'\n",
    "    else:\n",
    "        return 'Mutant?'\n",
    "    \n",
    "def correct(protein):\n",
    "    protein = protein.replace('PCBP1 100', 'PCBP1 L100')\n",
    "    protein = protein.replace('hnRNP C', 'hnRNPC')\n",
    "    protein = protein.replace('hnRNP D', 'hnRNPD')\n",
    "    protein = protein.upper()\n",
    "    return protein\n",
    "\n",
    "pma_dir = '/Users/dp/pma/'\n",
    "xlLoad = xlLoader.xlLoader(f\"{pma_dir}/percentCrosslinked.xlsx\")\n",
    "(xl_rate, recurrent) = xlLoad.load()\n",
    "xl_rate['Protein'] = [correct(p) for p in xl_rate['Protein']]\n",
    "xl_rate['Category'] = [categorize(p) for p in xl_rate.Protein]\n",
    "#xl_rate = xl_rate.loc[[x!='Mutant?' for x in xl_rate.Category], :]\n",
    "#print(xl_rate)\n",
    "\n",
    "def mean_of_label(label, xl_df):\n",
    "    sub = xl_df.loc[[x==label for x in xl_df['Label']], :]\n",
    "    g = dict(sub.groupby(by=['Protein'])['Value'].apply(np.mean))\n",
    "    #print(g)\n",
    "    return g\n",
    "\n",
    "xl_means = {}\n",
    "for col in set(xl_rate.Label):\n",
    "    try:\n",
    "        xl_means[col] = mean_of_label(col, xl_rate)\n",
    "    except:\n",
    "        pass  # Not numeric.\n",
    "xl_rate_mean = xl_means['% XL (minimal region)']\n",
    "\n",
    "xl_means['fmol RNA (whole lane)'] = {\n",
    "    protein:xl_means['% XL (whole lane)'].get(protein, -1E6)*100*xl_means['pmol protein'].get(protein, -1E6)*1000 for protein in set(xl_rate.Protein)}\n",
    "#xl_rate_mean = xl_rate_mean.T.to_dict()\n",
    "\n",
    "def _fl(x):\n",
    "    if type(x) != type(''):\n",
    "        return float(x)\n",
    "    return float(x.replace(',', ''))\n",
    "\n",
    "fname = '/Users/dp/pma/dataAndScripts/clip/miseq/Runs/200327/stats_in_scheme.xlsx'\n",
    "fname = '/Users/dp/pma/stats_in_scheme.xlsx'\n",
    "fname = '/Users/dp/pma/dataAndScripts/clip/RepEnrich2/meta/stats_in_scheme.xlsx'\n",
    "\n",
    "stats_df = pandas.read_excel(fname)\n",
    "stats_df['Gene'] = [x.replace(':', ' ') for x in stats_df.Gene]\n",
    "stats_df['Protein'] = [correct(p) for p in stats_df['Gene']]\n",
    "stats_df['Category'] = [categorize(p) for p in stats_df.Protein]\n",
    "#stats_df = stats_df.loc[[x!='Mutant?' for x in stats_df.Category], :]\n",
    "stats_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "stats_df['% XL (minimal region)'] = [xl_rate_mean.get(protein.replace('-', ' '), np.nan) for protein in stats_df.Protein]\n",
    "for col, _dict in xl_means.items():\n",
    "    stats_df[col] = [_dict.get(protein, np.nan) for protein in stats_df.Protein]\n",
    "    \n",
    "print(stats_df.head())\n",
    "print('------')\n",
    "\n",
    "#stats_df['Mapped reads (bedgraph)'] = [ for x in stats_df['Mapped reads (bedgraph)']]\n",
    "stats_df['% left split reads after inital removal of empty adapters'] = [\n",
    "    100*x/y for x,y in zip(stats_df['r1r2_clipped Reads'], stats_df['r1r2_split Reads'])] \n",
    "stats_df['% mapped of split reads'] = [\n",
    "    100*_fl(x)/y for x,y in zip(stats_df['Mapped reads (bedgraph)'], stats_df['r1r2_split Reads'])] \n",
    "stats_df['% mapped of non-empty reads'] = [\n",
    "    100*_fl(x)/y for x,y in zip(stats_df['Mapped reads (bedgraph)'], stats_df['r1r2_clipped Reads'])] \n",
    "\n",
    "spat = re.compile('(.+) \\((.+)%\\)')\n",
    "\n",
    "def separate_percents(_str):\n",
    "    \"\"\"Expect _str is of the format '2,122,888 (40.7%)'.\"\"\"\n",
    "    if type(_str) != type(''):\n",
    "        return 0, 0\n",
    "    pat = spat.search(_str)\n",
    "    if pat is not None:\n",
    "        perc = pat.group(2)\n",
    "        count = int(pat.group(1).replace(',', ''))\n",
    "        return count, perc\n",
    "    return 0, 0\n",
    "\n",
    "\n",
    "for col in [\n",
    "    'Mapped reads at autosomes',\n",
    "    'Mapped reads at chrX',\n",
    "    'Mapped reads at chrY',\n",
    "    'Mapped reads at rRNA',\n",
    "    'Mapped reads at Other genomic sequence',\n",
    "    'Mapped reads at repeats'\n",
    "    ]:\n",
    "    count_perc = [separate_percents(_str) for _str in stats_df[col]]\n",
    "    stats_df[col + ' (N)'] = [float(x[0]) for x in count_perc]\n",
    "    stats_df[col + ' (%)'] = [float(x[1]) for x in count_perc]\n",
    "    \n",
    "    \n",
    "def scatter_text(x, y, text_column, data, title, xlabel, ylabel):\n",
    "    \"\"\"Scatter plot with country codes on the x y coordinates\n",
    "       Based on this answer: https://stackoverflow.com/a/54789170/2641825\"\"\"\n",
    "    # Create the scatter plot\n",
    "    p1 = sns.scatterplot(x, y, data=data, size = 8, legend=False)\n",
    "    # Add text besides each point\n",
    "\n",
    "    # Set title and axis labels\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    return p1\n",
    "\n",
    "def make_scatterplot_and_excel_file(stats_df, x='% XL (minimal region)', y='% XL (minimal region)'):\n",
    "    stats_df['log10 ' + x] = np.log10(stats_df[x])\n",
    "    x='log10 ' + x\n",
    "    #y='% mapped of non-empty reads'\n",
    "    #y='% left split reads after inital removal of empty adapters'\n",
    "    p1 = sns.lmplot(x=x,y=y,\n",
    "               #y='% left split reads after inital removal of empty adapters',\n",
    "              hue='Category', data=stats_df, fit_reg=False)\n",
    "\n",
    "\n",
    "    for line in range(0,stats_df.shape[0]):\n",
    "        if not np.isnan(stats_df[x][line]):\n",
    "            pass\n",
    "            #if stats_df['Category'][line] != 'Mutant?':\n",
    "            #    continue\n",
    "            #p1.axes.flatten()[0].text(stats_df[x][line]+0.01, stats_df[y][line], \n",
    "            #         stats_df['Protein'][line], horizontalalignment='left', \n",
    "            #         size='small', color='black')#, weight='semibold')\n",
    "    plt.show(); plt.clf(); plt.close()\n",
    "\n",
    "    #print(stats_df.head())\n",
    "\n",
    "\n",
    "def write_excel(fname, stats_df):\n",
    "    writer = pandas.ExcelWriter(os.path.dirname(fname) + '/edited_stats_in_scheme.xlsx', engine='xlsxwriter')\n",
    "    stats_df.to_excel(writer, sheet_name='Sheet1')\n",
    "    # Get the xlsxwriter workbook and worksheet objects.\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "    # Apply a conditional format to the cell range.\n",
    "    first_row = 1\n",
    "    last_row = len(stats_df.index)\n",
    "\n",
    "    col_range = {}\n",
    "    for col_number, colname in enumerate(stats_df.columns, start=1):\n",
    "        col_range[colname] = (first_row, col_number, last_row, col_number)\n",
    "        \n",
    "    import xlsxwriter\n",
    "    for colname in stats_df.columns:\n",
    "        worksheet.conditional_format(xlsxwriter.utility.xl_range(*col_range[colname]),\n",
    "             {'type': '3_color_scale', 'min_color': 'green', 'mid_color': 'white', 'max_color': 'red'})\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()\n",
    "\n",
    "write_excel('/Users/dp/pma/dataAndScripts/clip/RepEnrich2/meta/', stats_df)\n",
    "make_scatterplot_and_excel_file(stats_df, x='fmol RNA (minimal region)', y='pmol protein')\n",
    "make_scatterplot_and_excel_file(stats_df, x='fmol RNA (whole lane)',  y='% left split reads after inital removal of empty adapters')\n",
    "make_scatterplot_and_excel_file(stats_df, x='fmol RNA (minimal region)', y='% mapped of split reads')\n",
    "make_scatterplot_and_excel_file(stats_df, x='% XL (minimal region)', y='% mapped of split reads')\n",
    "make_scatterplot_and_excel_file(stats_df, x='% XL (minimal region)', y='% left split reads after inital removal of empty adapters')\n",
    "make_scatterplot_and_excel_file(stats_df, x='% left split reads after inital removal of empty adapters', y='% mapped of split reads')\n",
    "make_scatterplot_and_excel_file(stats_df, x='fmol RNA (minimal region)', y='% left split reads after inital removal of empty adapters')\n",
    "make_scatterplot_and_excel_file(stats_df, x='% XL (minimal region)', y='Mapped reads at autosomes (%)')\n",
    "make_scatterplot_and_excel_file(stats_df, x='fmol RNA  (whole lane)',  y='% left split reads after inital removal of empty adapters')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
