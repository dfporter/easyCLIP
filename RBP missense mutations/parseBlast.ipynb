{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, collections, re, pandas, os, glob\n",
    "import Bio\n",
    "import Bio.SeqIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class convert_uniprot():\n",
    "    \n",
    "    def __init__(\n",
    "        self, table_fname: str = '/Users/dp/pma/RBP missense mutations/domains/uniprot_gene_id_to_symbol.txt'):\n",
    "        \n",
    "        self.df = pandas.read_csv(table_fname, sep='\\t')\n",
    "        self.uni_to_name = dict(zip(self.df['From'], self.df['To']))\n",
    "        #print(self.df)\n",
    "\n",
    "    def convert(self, uniprot_id: str):\n",
    "        uniprot_id = uniprot_id.split('.')[0]\n",
    "        return self.uni_to_name.get(uniprot_id, uniprot_id)\n",
    "    \n",
    "    def is_uniprot(self, uniprot_id):\n",
    "        uniprot_id = uniprot_id.split('.')[0]\n",
    "        if uniprot_id in self.uni_to_name:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "uniprot_id_converter = convert_uniprot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_blast(blast_json_filename: str) -> str:\n",
    "    a = json.load(open(blast_json_filename))\n",
    "    blast = a['BlastOutput2']\n",
    "\n",
    "    hits = {}\n",
    "    for entry in blast:\n",
    "\n",
    "        report = entry['report']['results']\n",
    "        \n",
    "        if 'bl2seq' in report:\n",
    "            report = report['bl2seq']#['search_target']\n",
    "            query = report[0]['query_title']\n",
    "            hits[query] = collections.defaultdict(list)\n",
    "            \n",
    "            for m in [_ for _ in report if len(_['hits'])]:\n",
    "                for hit in m['hits']:#[_ for _ in m['hits'] if _['evalue'] < 1E-10]:\n",
    "\n",
    "                    match_name = hit['description'][0]['title']\n",
    "\n",
    "                    for alignment in hit['hsps']:\n",
    "                        if alignment['evalue'] < 1E-50:\n",
    "                            hits[query][match_name].append(alignment['evalue'])\n",
    "                            \n",
    "        else:\n",
    "            report = report['search']\n",
    "            query = report['query_title']\n",
    "            hits[query] = collections.defaultdict(list)\n",
    "            \n",
    "            #print(report)\n",
    "            for hit in report['hits']:\n",
    "                match_name = hit['description'][0]['id']\n",
    "                \n",
    "                m = re.search('sp\\|(.+)\\|', match_name)\n",
    "                #print(match_name)\n",
    "                if m is not None and uniprot_id_converter.is_uniprot(m.group(1)):\n",
    "                    match_name = uniprot_id_converter.convert(m.group(1))\n",
    "                    \n",
    "                for alignment in hit['hsps']:\n",
    "                    if alignment['evalue'] < 1E-50:\n",
    "                        hits[query][match_name].append(alignment['evalue'])\n",
    "                #print(hit, match_name)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    rows = ''\n",
    "    rows_no_fname = ''\n",
    "\n",
    "    queries = sorted(hits, key = lambda x: float(re.search('[^-]*-[A-Za-z]*(\\d+)_', x).group(1)))\n",
    "\n",
    "    for query in queries:\n",
    "        s = ','.join(hits[query])\n",
    "        rows += f'{query}\\t{s}'\n",
    "        rows_no_fname += f'{s}'\n",
    "        \n",
    "        if len(hits[query]) == 1:\n",
    "            gene_name = s.split('_')[0]\n",
    "            rows += f'\\t{gene_name}'\n",
    "        else:\n",
    "            rows += '\\t'\n",
    "            \n",
    "        rows += '\\n'\n",
    "        rows_no_fname += '\\n'\n",
    "    \n",
    "    print(rows)\n",
    "    print('---')\n",
    "    print(rows_no_fname)\n",
    "    print('---')\n",
    "    return rows\n",
    "\n",
    "input_filename = '/Users/dp/Desktop/sanger/seqs/191011_maxipreps_missense_pSLX3/U1BKW19Z114-Alignment.json'\n",
    "input_filename = '/Users/dp/Desktop/sanger/seqs/191010_minipreps_missense_pSLX3/TZ4CJWR5114-Alignment.json'\n",
    "input_filename = '/Users/dp/Desktop/sanger/seqs/191017_pSLX3_maxipreps_missense/UKTE09DF114-Alignment.json'\n",
    "input_filename = '/Users/dp/Desktop/sanger/seqs/191018_maxipreps_missense_pSLX4_Ct_except_PCBP1_is_pSLX3/UPKNZDWC114-Alignment.json'\n",
    "input_filename = '/Users/dp/Desktop/sanger/seqs/191028_maxiprep_missense_both_N_and_C_all_no_uORF/VGUSHWK111N-Alignment.json'\n",
    "#input_filename = '/Users/dp/Desktop/sanger/seqs/191019_maxiprep_cds_sequencing_verifications_missense/UYC92776114-Alignment.json'\n",
    "input_filename = '/Users/dp/Desktop/sanger/seqs/191210_rpl5_rpl10_in_pSLX4_and_upf2_pSLX3/Z58M621R114-Alignment.json'\n",
    "input_filename = '/Users/dp/Desktop/sanger/seqs/200117_UPF2_DIS3_SMAD3_SMAD4_BRCA1_OAS1_BCLAF1_all_Nt_pSLX3_except_BCLAF1_Ct/26NJZ0YA114-Alignment.json'\n",
    "input_filename = '/Users/dp/Desktop/sanger/seqs/200117_UPF2_DIS3_SMAD3_SMAD4_BRCA1_OAS1_BCLAF1_all_Nt_pSLX3_except_BCLAF1_Ct/26NMC1R6014-Alignment.json'\n",
    "input_filename = '/Users/dp/Desktop/sanger/seqs/200122_BARD1_BRCA1_sequencixng/2H5096ZD016-Alignment.json'\n",
    "input_filename = '/Users/dp/Desktop/sanger/seqs/190219_SMAD3_BRCA1_OTHERS_RESEQ_PSLX3_except_BCLAF1_is_pSLX4/4XHTKXTS016-Alignment.json'\n",
    "#+input_filename = '/Users/dp/Desktop/sanger/seqs/190218_SMAD3_4_BRCA1_PLSX3_OTHERS_ALL_PSLX3_OR_PSLX4/4UKMRK2S014-Alignment.json'\n",
    "out = parse_blast(input_filename)\n",
    "\n",
    "with open(os.path.dirname(input_filename) + '/parsed_blast.txt', 'w') as f:\n",
    "    f.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_uORF_and_tag_status_in_dir(input_folder: str = None, input_filename: str = None) -> str:\n",
    "    \n",
    "    #  Outputs:\n",
    "    lines = ''\n",
    "    lines_just_result = ''\n",
    "    \n",
    "    # Input file, not folder:\n",
    "    if input_folder is None:\n",
    "\n",
    "        input_folder = os.path.dirname(input_filename)\n",
    "        print(f\"Parsing fasta in {input_folder}.\")\n",
    "        \n",
    "        #try:\n",
    "        lines_list = []\n",
    "        for record in Bio.SeqIO.parse(input_filename, 'fasta'):\n",
    "            result = check_uORF_and_tag_status_in_seq(record.seq)\n",
    "            lines_list.append([record, result])\n",
    "\n",
    "        lines_list = sorted(lines_list, key = lambda x: float(re.search('[^-]*-[A-Za-z]*(\\d+)_', os.path.basename(x[0].name)).group(1)))\n",
    "\n",
    "        for (record, result) in lines_list:\n",
    "            lines += record.name + '\\t' + result\n",
    "            lines_just_result += result\n",
    "            \n",
    "        #lines = ''.join(lines_list)\n",
    "        print(lines)\n",
    "        #print(lines)\n",
    "        print(lines_just_result)\n",
    "\n",
    "        return\n",
    "        \n",
    "        #except:\n",
    "        #    print(\"Failed to read input file as a set of fastas. Instead looking in its directory.\")\n",
    "    # Input folder:\n",
    "    fnames = glob.glob(input_folder + '/*.seq')\n",
    "\n",
    "    queries = sorted(fnames, key = lambda x: float(re.search('[^-]*-[A-Za-z]*(\\d+)_', os.path.basename(x)).group(1)))\n",
    "    \n",
    "\n",
    "    for fname in queries:\n",
    "        result = check_uORF_and_tag_status_in_seq(Bio.SeqIO.read(fname, 'fasta').seq)\n",
    "        lines += os.path.basename(fname) + '\\t' + result\n",
    "        lines_just_result += result\n",
    "    print(lines)\n",
    "    print(lines_just_result)\n",
    "    \n",
    "def check_uORF_and_tag_status_in_seq(seq: str) -> str:\n",
    "    nt_tag_seq = 'ATGGATTATAAAGATGACGACGATAAAGCAGGTTACCCATACGATGTGCCTGACTATGCTGCAGGTTCACATCATCACCACCATCATGGATCCATG'\n",
    "    nt_tag_seq_no_final_ATG = nt_tag_seq[:-3]\n",
    "    \n",
    "    downstream_as_reverse_complement = 'TCCACCACACTGGACTAGTGGATC'\n",
    "    primer_direction = '(F)'\n",
    "    if downstream_as_reverse_complement in seq:\n",
    "        #print('Rev primer')\n",
    "        primer_direction = '(R)'\n",
    "    \n",
    "    if primer_direction == '(F)':\n",
    "        no_uORF = 'CTGGCATAACGACTAA'\n",
    "        uORF = 'ATGGCATAACGACTAA'\n",
    "        if uORF in seq and (no_uORF not in seq):\n",
    "            uORF_status = 'uORF.'\n",
    "        elif uORF not in seq and (no_uORF in seq):\n",
    "            uORF_status = 'No uORF.'\n",
    "        else:\n",
    "            uORF_status = 'Unclear uORF.'\n",
    "\n",
    "        if nt_tag_seq in seq:\n",
    "            tag = 'Has entire tag.'\n",
    "        elif nt_tag_seq_no_final_ATG in seq:\n",
    "            tag = \"See entire tag, but no second ATG starting the protein of interest (may be intentional).\"\n",
    "        else:\n",
    "            tag = \"Don't see entire tag.\"\n",
    "    else:\n",
    "        uORF_status = ''\n",
    "        tag = ''\n",
    "    #print(uORF_status, tag)\n",
    "    \n",
    "    C_terminal_his_r = 'CACTAATGATGGTGGTGATG'  # Rev complement.\n",
    "    C_terminal_his_f = 'CATCACCACCATCATTAGTG'  # Forward.\n",
    "    \n",
    "    C_terminal_tag = ''\n",
    "    if C_terminal_his_f in seq:\n",
    "        C_terminal_tag = 'C-t (F).'\n",
    "    if C_terminal_his_r in seq:\n",
    "        C_terminal_tag = 'C-t (R).'\n",
    "\n",
    "    if 'TCTTTATAATCTGGATC' in seq:\n",
    "        if 'TCTTTATAATCTGGATCTTA' in seq or \\\n",
    "           'TCTTTATAATCTGGATCTCA' in seq or \\\n",
    "           'TCTTTATAATCTGGATCCTA' in seq:  \n",
    "           #'TCTTTATAATCTGGATC'\n",
    "            #'TGA>TCA TAA>TTA TAG>CTA'\n",
    "            C_terminal_tag += ' Has a stop before C-t tag. Not usable.'\n",
    "    return f'{primer_direction} {uORF_status} {tag} {C_terminal_tag}\\n'\n",
    "\n",
    "\n",
    "check_uORF_and_tag_status_in_dir(input_filename='/Users/dp/Desktop/sanger/seqs/200403_re_maxi_prep_for_more_vector/all.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
