{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, matplotlib, pandas, collections, importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import pandas, re\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from typing import List, Union, Mapping, Tuple\n",
    "from pprint import pprint\n",
    "from scipy import stats\n",
    "\n",
    "import heatmaper as hm\n",
    "import xlLoader\n",
    "import stabilityLoader\n",
    "importlib.reload(stabilityLoader)\n",
    "pma_dir = '/Users/dp/pma/'\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rc('font',**{'family':'sans-serif','sans-serif':['Arial']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import NormalDist\n",
    "from scipy.stats import norm\n",
    "\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    #https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data\n",
    "    if len(data) < 2:\n",
    "        return np.nan\n",
    "    dist = NormalDist.from_samples(data)\n",
    "    z = NormalDist().inv_cdf((1 + confidence) / 2.)\n",
    "    h = dist.stdev * z / ((len(data) - 1) ** .5)\n",
    "    return dist.mean - h, dist.mean + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(xlLoader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def get_xl_pval_df_from_ttest_vs_wt(xl):\n",
    "    mut_to_pval = {}\n",
    "    mut_to_ci = {}\n",
    "\n",
    "    for prot in set([_ for _ in xl.Protein if ' ' in _]):\n",
    "        sub = xl.loc[[x==prot for x in xl.Protein], 'Value vs WT'].to_numpy()\n",
    "        res = scipy.stats.ttest_1samp(sub, 0.)\n",
    "        #ci = confidence_interval(sub)\n",
    "        mut_to_pval[prot] = np.log10(res.pvalue)\n",
    "        #mut_to_ci[prot] = ci\n",
    "\n",
    "    for prot in [_ for _ in xl.Protein if ' ' not in _]:\n",
    "        mut_to_pval[prot] = 1.\n",
    "\n",
    "    xl_pval_df = pandas.DataFrame.from_dict(mut_to_pval, 'index').T\n",
    "    xl_pval_df.index = ['P value']\n",
    "    \n",
    "    #ci_df = pandas.DataFrame.from_dict(mut_to_ci, 'index').T\n",
    "    return xl_pval_df\n",
    "\n",
    "\n",
    "def sorted_gids(gid, xl):\n",
    "    _df = xl.loc[[bool(x==gid[1]) for x in xl.Protein], :]\n",
    "    gids = list(set(_df.loc[:, 'Group_ID']))\n",
    "    to_exp_decimal = {(exp, protein, rep): float(str((exp.split('xp')[-1])) + '.' + str(rep.split(' ')[-1])) \\\n",
    "                      for (exp, protein, rep) in gids}\n",
    "    gids = sorted(gids, key=lambda x: to_exp_decimal[x])\n",
    "    return gids\n",
    "\n",
    "def sorted_all_gids_with_the_same_wt_protein(protein, xl):\n",
    "    _df = xl.loc[[bool(  x.split(' ')[0]==protein.split(' ')[0]  ) for x in xl.Protein], :]\n",
    "    gids = list(set(_df.loc[:, 'Group_ID']))\n",
    "    to_exp_decimal = {(exp, protein, rep): float(exp.split('xp')[-1]) for (exp, protein, rep) in gids}\n",
    "    gids = sorted(gids, key=lambda x: to_exp_decimal[x])\n",
    "    return gids\n",
    "\n",
    "\n",
    "def define_all_batches(xl):\n",
    "    to_batches = {}\n",
    "    for protein in set(xl['Protein']):\n",
    "        to_batches[protein] = batches_for_a_protein(protein, xl)\n",
    "    xl['Batch'] = [to_batches[protein][exp, rep] for protein, exp, rep in zip(\n",
    "        xl.Protein, xl.Exp, xl.Rep)]\n",
    "    \n",
    "def batches_for_a_protein(protein, xl):\n",
    "\n",
    "    _sorted = sorted_all_gids_with_the_same_wt_protein(protein, xl)\n",
    "    exp_rep_pairs = [(_exp, _rep) for _exp, _prot, _rep in _sorted]\n",
    "    # Remove duplicates keeping list order.\n",
    "    _ = [] \n",
    "    [_.append(x) for x in exp_rep_pairs if x not in _] \n",
    "    exp_rep_pairs = _\n",
    "    to_batch = {exp_rep_pair:n for n, exp_rep_pair in enumerate(exp_rep_pairs, start=1)}\n",
    "    return to_batch\n",
    "\n",
    "def batch1(gid, xl):\n",
    "    return xl.loc[[bool(prot==gid[1] and batch==1) for prot, batch in zip(xl.Protein, xl.Batch)], :]\n",
    "    \n",
    "def subtract_pair_from_batch1(gid, xl):\n",
    "    val = xl.loc[[groupid==gid for groupid in xl.Group_ID], 'vs_protein_mean'].to_numpy()[0]    \n",
    "    val_batch1 = batch1(gid, xl)\n",
    "    if len(val_batch1.index):\n",
    "        val_batch1 = val_batch1['vs_protein_mean'].to_numpy()[0]\n",
    "        return val - val_batch1\n",
    "    print(f\"No batch1 found for {gid}\")\n",
    "    return np.nan\n",
    "\n",
    "def pair_batches(xl):\n",
    "    b2 = xl.loc[[x!=1 for x in xl.Batch], :]\n",
    "    arr = []\n",
    "    for protein in [x for x in set(b2['Protein']) if ' ' in x]:  # For each mutant.\n",
    "        sub = b2.loc[[x==protein for x in b2.Protein], '-batch1'].to_numpy()\n",
    "        wt = b2.loc[[x==protein.split(' ')[0] for x in b2.Protein], '-batch1'].to_numpy()\n",
    "        for n, val in enumerate(sub):\n",
    "            if len(wt) > n and not (np.isnan(wt[n]) or np.isnan(sub[n])):\n",
    "                arr.append([wt[n], sub[n]])\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_xl_pval_df_from_norm(xl, mean, stddev):\n",
    "    mut_to_pval = {}\n",
    "    \n",
    "    n = norm(loc=mean, scale=stddev)#.cdf([1.3, 1.3])\n",
    "    #print(np.product([1-v for v in a]))\n",
    "    for prot in set([_ for _ in xl.Protein if ' ' in _]):\n",
    "        sub = xl.loc[[x==prot for x in xl.Protein], 'vs_protein_mean'].to_numpy()\n",
    "        \n",
    "        #for val in sub:\n",
    "        #    print(val, norm(loc=mean, scale=stddev).cdf(3.))\n",
    "            \n",
    "        print(sub)\n",
    "        \n",
    "        # pvals for increase.\n",
    "        pval_inc = 1-n.cdf(np.mean(sub))\n",
    "\n",
    "        # pvals for decrease.\n",
    "        pval_dec = n.cdf(np.mean(sub))\n",
    "        \n",
    "        lower = min([pval_inc, pval_dec])\n",
    "        \n",
    "        print(f\"{prot}: {pval_inc}, {pval_dec}\")\n",
    "        \n",
    "#get_xl_pval_df_from_norm(xl, mean, stddev)\n",
    "xl_pval_df = get_xl_pval_df_from_ttest_vs_wt(xl)\n",
    "#print(xl_pval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cross-linking data.\n",
    "xlLoad = xlLoader.xlLoader(f\"{pma_dir}/percentCrosslinked.xlsx\")\n",
    "(df, recurrent) = xlLoad.load()\n",
    "xl = recurrent.loc[recurrent['Label']=='% XL (minimal region)',:].copy()\n",
    "xlLoad.as_fraction_of_wt(xl)\n",
    "\n",
    "# To investigate batch effects, define batches.\n",
    "define_all_batches(xl)\n",
    "\n",
    "# Normalize all the the WT protein mean.\n",
    "# xl['vs_protein_mean'] = XL/(average WT protein XL)\n",
    "prot_means = xl.groupby(by=['Protein'])['Value'].mean().to_dict()\n",
    "xl['vs_protein_mean'] = [(val)/max([0.001, prot_means[p.split(' ')[0]]]) for val, p, exp in zip(xl['Value'], xl['Protein'], xl.Exp)]\n",
    "\n",
    "# Use batch definitions to get the change in signal from batch 1 for each protein.\n",
    "# xl['-batch1'] = (XL{batch x} - XL{batch 1})/(average WT protein XL)\n",
    "xl['-batch1'] = [subtract_pair_from_batch1(gid, xl) for gid in xl.Group_ID]\n",
    "\n",
    "# Pair (WT, MUT) for each batch for each protein (of -batch1 values, batch1 itself not included).\n",
    "# These are [(XL{WT batch 2} - XL{WT batch 1})/(average WT protein XL),\n",
    "#           (XL{MUT batch 2} - XL{MUT batch 1})/(average WT protein XL)].\n",
    "wt_mut_pairs = pair_batches(xl)\n",
    "\n",
    "# Create df for sns.lmplot.\n",
    "arrdf = pandas.DataFrame(wt_mut_pairs)\n",
    "arrdf.columns = ['WT', 'MUT']\n",
    "\n",
    "# Get the parameters for a linear regression.\n",
    "x=[x[0] for x in wt_mut_pairs]\n",
    "y=[x[1] for x in wt_mut_pairs]\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x, y)\n",
    "print(f\"slope={slope}, intercept={intercept}, R={r_value}, p={p_value}, std_err={std_err}, R^2={r_value**2}\")\n",
    "#plt.scatter(x=[x[0] for x in arr], y=[x[1] for x in arr], c='k', alpha=0.3)\n",
    "\n",
    "# sns.lmplot the -batch1 values.\n",
    "sns.lmplot(x='WT', y='MUT', data=arrdf)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.close()\n",
    "\n",
    "############\n",
    "# Get a Protein->average value dict.\n",
    "_ = xl.groupby(by=['Protein'])['Value'].mean().to_dict()\n",
    "\n",
    "# Subset to proteins with a sufficiently high WT protein mean value.\n",
    "xl = xl.loc[[prot_means[p]>0.1 for p in xl['WT protein']], :]\n",
    "\n",
    "# log2 transform\n",
    "xl['vs_protein_mean'] = np.log2(xl['vs_protein_mean'])\n",
    "xl = xl.loc[[np.isfinite(x) for x in xl['vs_protein_mean']], :]\n",
    "\n",
    "# Plot val/(WT mean), including outliers.\n",
    "ax = sns.distplot(xl['vs_protein_mean'], kde=True)\n",
    "\n",
    "# Subset to val/(WT mean) below 2 to remove outliers, get the mean and std dev, and fit a normal distribution.\n",
    "vm = xl['vs_protein_mean'].to_numpy()\n",
    "vm = vm[vm<2]\n",
    "vm = vm[vm>-2]\n",
    "mean, stddev = (np.mean(vm), np.var(vm)**0.5)\n",
    "fit_norm_vals = np.random.normal([np.mean(vm)], [np.var(vm)**0.5], size=1000).T\n",
    "\n",
    "# Print mean/std dev.\n",
    "print(f\"mean={mean}, stddev={stddev}\")\n",
    "\n",
    "# Plot the fit normal distribution.\n",
    "sns.distplot(fit_norm_vals, ax=ax, hist=False, fit=norm, kde=False)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.close()\n",
    "\n",
    "# Define batch_ID column.\n",
    "q = xl.groupby(by=['Protein'])['Group_ID']\n",
    "print(q.get_group('A1CF').to_list())\n",
    "xl['batch_ID'] = [q.get_group(x).to_list() + q.get_group(x.split(' ')[0]).to_list() for x in xl.Protein]\n",
    "print(xl.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlLoad = xlLoader.xlLoader(f\"{pma_dir}/percentCrosslinked.xlsx\")\n",
    "(df, recurrent) = xlLoad.load()\n",
    "sns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine p values from t statistics and add to xl dataframe.\n",
    "\n",
    "\n",
    "# Load cross-linking data.\n",
    "xlLoad = xlLoader.xlLoader(f\"{pma_dir}/percentCrosslinked.xlsx\")\n",
    "(df, recurrent) = xlLoad.load()\n",
    "xl = recurrent.loc[recurrent['Label']=='% XL (minimal region)',:].copy()\n",
    "xlLoad.as_fraction_of_wt(xl)\n",
    "\n",
    "# To investigate batch effects, define batches.\n",
    "define_all_batches(xl)\n",
    "def add_pvalues_using_var_across_all_samples(xl):\n",
    "    # Normalize all to the WT protein mean.\n",
    "    # xl['vs_protein_mean'] = XL/(average WT protein XL)\n",
    "    # Not used here currently.\n",
    "    prot_means = xl.groupby(by=['Protein'])['Value'].mean().to_dict()\n",
    "    xl['vs_protein_mean'] = [(val)/max([0.001, prot_means[p.split(' ')[0]]]) for val, p, exp in zip(xl['Value'], xl['Protein'], xl.Exp)]\n",
    "\n",
    "    # Do we need this?\n",
    "    xl = xl.loc[[np.isfinite(x) for x in xl['log2 Value vs WT']], :]\n",
    "\n",
    "    # Only sufficiently high values used for determining variance, and remove WTs (all WT = 1).\n",
    "    mut_only = xl.loc[[x>0.1 for x in xl['Value']], :]\n",
    "    mut_only = mut_only.loc[[' ' in x for x in mut_only.Protein], :]\n",
    "\n",
    "    value_vs_wt_by_prot_mut_only = mut_only.groupby('Protein')['Value vs WT'].apply(np.array)\n",
    "    deltas = []\n",
    "    for x in value_vs_wt_by_prot_mut_only:\n",
    "        [deltas.append(x[n] - x[0]) for n in range(1, len(x))]\n",
    "\n",
    "    print(f\"Estimating total variance from {len(deltas)} values of MUT/WT. These are deltas of MUT/max([WT, 10**-6])).\")\n",
    "    print(f\"Each value is MUT(batch x)/WT(batch x) - MUT(batch 1)/WT(batch 1).\")\n",
    "    print(f\"These deltas are: {deltas}.\")\n",
    "\n",
    "    variance = np.var(deltas)\n",
    "    print(f\"variance={variance}, mean={np.mean(deltas)}\")\n",
    "\n",
    "    def t_statistic(arr, variance):\n",
    "        n = len(arr)\n",
    "        t = np.mean(arr) - 1\n",
    "        sample_var = (variance + np.var(arr))/2  # Will this be valid?\n",
    "        t = t/(sample_var/np.sqrt(n))\n",
    "        pval = stats.t.sf(np.abs(t), n-1)*2\n",
    "        #print(f\"t-statistic = {t:6.3f} pvalue = {pval:6.4f}\")\n",
    "        return t, pval\n",
    "\n",
    "    value_vs_wt_by_prot = xl.groupby('Protein')['Value vs WT'].apply(np.array)\n",
    "    mut_to_pval = {}\n",
    "    for name, val in zip(value_vs_wt_by_prot.index, value_vs_wt_by_prot):\n",
    "        mut_to_pval[name] = t_statistic(val, variance)[1]\n",
    "        print(f\"{name}, {val}, pvalue = {mut_to_pval[name]:6.4f}\")\n",
    "        mean_wt_xl = prot_means[name.split(' ')[0]]\n",
    "        if mean_wt_xl < 0.01:\n",
    "            mut_to_pval[name] = 1.\n",
    "            print(f\"--> set pval to 1. because XL rate was < 0.01% (unreliable).\")\n",
    "\n",
    "    # Setting this column is the goal of this function:\n",
    "    xl['P value'] = [mut_to_pval.get(name, 1.) for name in xl.Protein]\n",
    "\n",
    "    # Diagnostic plot:\n",
    "    ax = sns.distplot(\n",
    "        deltas,\n",
    "        #fit=norm,#\n",
    "        #xl['log2 Value vs WT'], kde=True\n",
    "    )\n",
    "    delta_norm = np.random.normal([np.mean(deltas)], [np.var(deltas)**0.5], size=1000).T\n",
    "\n",
    "    sns.distplot(delta_norm, fit=norm, hist=False, kde=False, ax=ax)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "add_pvalues_using_var_across_all_samples(xl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
