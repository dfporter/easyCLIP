{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, os, sys, re, collections, importlib\n",
    "sys.path.append('/Users/dp/pma/')\n",
    "import sameRiver\n",
    "import sameRiver.biotypeLookupFileMaker\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from Bio.Seq import Seq\n",
    "import Bio\n",
    "import pprint\n",
    "from pprint import pprint as pp\n",
    "import primerMaker\n",
    "importlib.reload(primerMaker)\n",
    "from primerMaker import primerMaker\n",
    "\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "import time\n",
    "\n",
    "def _mk(x):\n",
    "    if not os.path.exists(x):\n",
    "        os.system('mkdir ' + x)\n",
    "_mk('gb/')\n",
    "_mk('fasta/')\n",
    "\n",
    "def download_gb(_id=\"BC040523\"):\n",
    "    Entrez.email = \"dfporter@stanford.edu\"\n",
    "    with Entrez.efetch(db=\"nucleotide\", rettype=\"gb\", retmode=\"text\", id=_id) as handle:\n",
    "        with open('gb/{}.gb'.format(_id), 'w') as f:\n",
    "            f.write(handle.read())\n",
    "        handle.close()\n",
    "        \n",
    "def download_all_gb(id_list):\n",
    "    for _id in id_list:\n",
    "        if type(_id) != type('') or (_id == 'Not found!') or (_id == 'nan'):\n",
    "            continue\n",
    "        if os.path.exists('gb/{}.gb'.format(_id)):\n",
    "            continue\n",
    "        try:\n",
    "            download_gb(_id=_id)\n",
    "        except:\n",
    "            print(\"Failed to download {}\".format(_id))\n",
    "        time.sleep(5)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_enst_gene_name_biotype_map_file(\n",
    "    gtf_filename='/opt/genome/ensembl_release94_GRCh38/gencode.v29.primary_assembly.annotation.exons_cds_only.gtf',\n",
    "    out_filename='enst_transcript_id_name_biotype_map.txt'):\n",
    "\n",
    "    rows = collections.defaultdict(dict)\n",
    "    \n",
    "    def re_result(search_result):\n",
    "        if search_result is None:\n",
    "            return ''\n",
    "        else:\n",
    "            return search_result.group(1)\n",
    "        \n",
    "    with open(gtf_filename) as f:\n",
    "        for li in f:\n",
    "            #s = li.rstrip('\\n').split('\\t')\n",
    "            txpt = re_result(re.search('transcript_id=* *\"*([^;\"]+)', li))     \n",
    "            name = re_result(re.search('gene_name=* *\"*([^;\"]+)', li))\n",
    "\n",
    "            biotype = re_result(re.search('transcript_biotype=* *\"*([^;\"]+)', li))\n",
    "            if (biotype == ''):\n",
    "                biotype = re_result(re.search('biotype=* *\"*([^;\"]+)', li))\n",
    "            if biotype == '':\n",
    "                biotype = re_result(re.search('transcript_type=* *\"*([^;\"]+)', li))\n",
    "            if biotype == '':\n",
    "                biotype = re_result(re.search('gene_type=* *\"*([^;\"]+)', li))\n",
    "            if biotype == '':\n",
    "                biotype = re_result(re.search('type=* *\"*([^;\"]+)', li))\n",
    "\n",
    "            if txpt == '':\n",
    "                continue\n",
    "            \n",
    "            if txpt not in rows:\n",
    "                rows[txpt] = {'transcript_id': txpt, 'gene_name': name, 'transcript_biotype': biotype,\n",
    "                             }\n",
    "    \n",
    "    with open(out_filename, 'w') as f:\n",
    "        keys = ['transcript_id', 'gene_name', 'transcript_biotype']\n",
    "        f.write('\\t'.join(keys) + '\\n')\n",
    "        for row in rows.values():\n",
    "            f.write('\\t'.join([row[x] for x in keys]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amigo = pandas.read_csv('listsOfRbps/rna_binding_genes_from_amigo.txt', sep='\\t', comment='#')['Gene name'].tolist()\n",
    "#print(amigo)\n",
    "gtf = '/opt/genome/ensembl_release94_GRCh38/gencode.v29.primary_assembly.annotation.exons_cds_only.gtf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download all the genbank sequences for MGC cDNA clones for RBPs with missense\n",
    "# mutations in cancer.\n",
    "\n",
    "def load_rbps(download: bool=False) -> pandas.DataFrame\n",
    "    df = pandas.read_excel('./RBP_high_freq_mutations.xlsx')\n",
    "\n",
    "    # Filtering.\n",
    "    df = df.loc[:, [x for x in df.columns if 'notes' not in x]]\n",
    "    df['URL'] = df['URL'].astype('str')\n",
    "    df['URL'] = [x.split('/')[-1] for x in df.URL]\n",
    "    df['Amigo?'] = [bool(x in amigo) for x in df['Gene']]\n",
    "\n",
    "    if download:\n",
    "        download_all_gb(df.URL)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_rbps(download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BamHI cut uORF Nt FHH (only see His tag in overlap primer.)\n",
    "\n",
    "# left_overlap = 'ACATCATCACCACCATCAT' # <- this failed\n",
    "#left_overlap = 'ACATCATCACCACCATCATGGA'\n",
    "left_overlap = 'ACATCATCACCACCATCATGGATCC'\n",
    "#right_overlap = 'CCACACTGGACTAGTGGATC' # <- as in the primer (antisense)\n",
    "right_overlap = 'GATCCACTAGTCCAGTGTGG' # <- as in the vector (sense)\n",
    "                #CCACACTGGACTAGTGGATC CTAGTGTCTCTGGGCCAAGG\n",
    "#        ACATCATCACCACCATCAT   ATGGAATCAAATCACAAATCCGGG\n",
    "# CELF L ACATCATCACCACCATCATGGAATG AACGGCACCCTGGA\n",
    "# eIFH L ACATCATCACCACCATCATGGAATG GCGGACTTCGACAC\n",
    "\n",
    "# R stitch  overlap region   stop  C-term of CDS\n",
    "# CELF R CCACACTGGACTAGTGGATC TCA GTAGGGCTTGCTGTC\n",
    "# hnRD R CCACACTGGACTAGTGGATC TTA GTATGGTTTGTAGCTATTTTGATGAC\n",
    "# eIFH R CCACACTGGACTAGTGGATC TCA TTCTTGCTCCTTTTGAACG\n",
    "# TIAL R CCACACTGGACTAGTGGATC TCA CTGTGTTTGGTAACTTGC\n",
    "# gblo.  CCACACTGGACTAGTGGATC TTA GTATGGTTTGTAGCTATTTTGATGACCACCTCGCCT\n",
    "#        CCACACTGGACTAGTGGATC\n",
    "#    TCCACCACACTGGACTAGTGGATC\n",
    "#.       CCACACTGGACTAGTGGATCTTACATCCTACATACAGGTGTTATTCCAA\n",
    "gblock_start = 'ACATCATCACCACCATCATGGAATGTCGGAGGAGCAGTTCGGAGGTGACGGAGCAGCAGCTGCTGCTAC'\n",
    "\n",
    "s = Seq(gblock_start[1:])\n",
    "sp = s.translate()\n",
    "print(sp)\n",
    "# SYKPY\n",
    "gblock_end = 'CAGGCGAGGTGGTCATCAAAATAGCTACAAACCATACTAAGATCCACTAGTCCAGTGTGG'\n",
    "\n",
    "g = Seq(gblock_end[1+3*12:])\n",
    "overlap_forward = Seq(gblock_end[37:])\n",
    "overlap_rc = overlap_forward.reverse_complement()\n",
    "print(overlap_rc)\n",
    "print(gblock_end[37:])\n",
    "g.translate()\n",
    "\n",
    "_0_rightstitch = 'TGGCAAGCAATAGCGCGGCGGCGAAAGCCGCACGC'\n",
    "_1_leftstitch = 'ATGGCGTGCGGCTTTCGCCGCCGCGCTATTGCTTG'\n",
    "print('   ' + Seq(_0_rightstitch).reverse_complement())\n",
    "print(_1_leftstitch)\n",
    "\n",
    "from Bio.Data import CodonTable\n",
    "standard_table = CodonTable.unambiguous_dna_by_id[1]\n",
    "print(standard_table)\n",
    "standard_table.back_table['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.ncbi.nlm.nih.gov/nuccore/BC040523\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import IUPAC\n",
    "\n",
    "def get_dna(_loc, seq_record):\n",
    "    seq = seq_record.seq\n",
    "    dna =  seq[_loc._start:_loc._end]#, IUPAC.ambiguous_dna)\n",
    "    if _loc._strand != 1:\n",
    "        dna = dna.reverse_complement()\n",
    "    return dna  # Seq object\n",
    "\n",
    "def find_mutation_to_convert(codon, aa):\n",
    "    bases = ['A', 'T', 'C', 'G']\n",
    "    possibilities = {}\n",
    "#    for nt in [0, 1, 2]:\n",
    "    for base in bases:\n",
    "        new_codon = base + codon[1:]\n",
    "        possibilities[str(base + codon[1:])] = str(new_codon.translate())\n",
    "    for base in bases:\n",
    "        new_codon = Seq(codon[0] + base + codon[2], IUPAC.ambiguous_dna)\n",
    "        possibilities[str(codon[0] + base + codon[2])] = str(new_codon.translate())\n",
    "    for base in bases:\n",
    "        new_codon = codon[:2] + base\n",
    "        possibilities[str(codon[:2] + base)] = str(new_codon.translate())        \n",
    "    #print(possibilities)\n",
    "    mutations = [x for x in possibilities if possibilities[x]==aa]\n",
    "    if len(mutations) < 1:\n",
    "        print(\"Could not find an appropriate mutation by SNV. Using an entirely different codon.\")\n",
    "        standard_table = CodonTable.unambiguous_dna_by_id[1]\n",
    "        return standard_table.back_table[aa]\n",
    "    else:\n",
    "        return mutations[0]\n",
    "\n",
    "def get_cds_from_genbank_record(seq_record):\n",
    "\n",
    "        # Did we annotate what to PCR?\n",
    "        highlighted_cds = 0\n",
    "        starts_with = 0\n",
    "\n",
    "        for feature in seq_record.features:\n",
    "            y = feature.__dict__\n",
    "            \n",
    "            if 'qualifiers' in y and 'label' in y['qualifiers']:\n",
    "                \n",
    "                if y['qualifiers']['label'][0] == 'CDS_to_amplify':\n",
    "                    highlighted_cds = feature\n",
    "                    # 0-based.\n",
    "                    if 'starts_with_aa_num' in y['qualifiers']:\n",
    "                        starts_with = int(y['qualifiers']['starts_with_aa_num'][0])\n",
    "                    else:\n",
    "                        starts_with = 0\n",
    "        if highlighted_cds:\n",
    "            cds = highlighted_cds\n",
    "        # If not, get the first CDS annotated.\n",
    "        else:\n",
    "            try:\n",
    "                cds = [x for x in seq_record.features if x.type=='CDS'][0]\n",
    "            except:\n",
    "                print(\"*\" * 14 + \"No CDS...\")\n",
    "                return\n",
    "        \n",
    "        cds_start = cds.location.start\n",
    "        cds_dna = seq_record.seq[cds.location.start:cds.location.end]\n",
    "        if cds.location.strand != 1:\n",
    "            cds_dna = Seq.reverse_complement(cds_dna)\n",
    "        cds_aa = cds_dna.translate()\n",
    "\n",
    "        return cds_dna, cds_aa, starts_with\n",
    "    \n",
    "def get_primers(fname, aa_wt, aa_n, aa_mut, gene_name='gene_name'): \n",
    "    \n",
    "    for seq_record in SeqIO.parse(fname, \"genbank\"):\n",
    "\n",
    "        print(seq_record.id)\n",
    "        #print(seq_record.features)\n",
    "\n",
    "        cds_dna, cds_aa, starts_with = get_cds_from_genbank_record(seq_record)\n",
    "        \n",
    "        aa_n -= starts_with\n",
    "    \n",
    "        #cds_dna = get_dna(cds.location, seq_record)\n",
    "        #if 'translation' in cds.qualifiers:\n",
    "        #    cds_aa = cds.qualifiers['translation'][0]\n",
    "        #else:\n",
    "        #    cds_aa = cds.translate(cds_dna)\n",
    "        print('aa_n = ', aa_n, ' seq length for cds: ', len(cds_dna))\n",
    "        if aa_n * 3 > len(cds_dna):\n",
    "            print(\"*\" * 14 + \"aa number out of bounds\")\n",
    "            return\n",
    "        \n",
    "        snp_left = (aa_n - 1) * 3\n",
    "        snp_right = aa_n * 3\n",
    "        codon = cds_dna[snp_left:snp_right]\n",
    "        context = cds_dna[snp_left-6:snp_right+6].translate()\n",
    "        print(\"Observed codon translation:\", codon.translate(), ' expected ', aa_wt)\n",
    "        print(\"Context: \", context)\n",
    "        \n",
    "        if aa_wt != codon.translate():\n",
    "            print(\"*\" * 14 + \"Observed aa did not match expected\")\n",
    "            print(\"Context: \", cds_dna[snp_left-6:snp_right+6].translate())\n",
    "            #return\n",
    "        \n",
    "        mutation = find_mutation_to_convert(codon, aa_mut)\n",
    "        \n",
    "        product_size_full = len(cds_dna)\n",
    "        product_size_left = len(cds_dna[:snp_right])\n",
    "        product_size_right = len(cds_dna[snp_left:])\n",
    "        \n",
    "        if os.path.exists('outputs/pcr_product_sizes.txt'):\n",
    "            f = open('outputs/pcr_product_sizes.txt', 'a')\n",
    "        else:\n",
    "            f = open('outputs/pcr_product_sizes.txt', 'w')\n",
    "            f.write(\"seqid\\tfull_cds_length\\tleft\\tright\\t-\\tCDS\\tmut\\n\")\n",
    "\n",
    "        f.write(f\"{gene_name}\\t{product_size_full}\\t{product_size_left}\")\n",
    "        f.write(f'\\t{product_size_right}')\n",
    "        f.write(\"\\t-\\t{}\\t{}\\n\".format(product_size_full/3 - 1, f\"{aa_wt}{aa_n}{aa_mut}\"))\n",
    "            \n",
    "        print(\"Mutation {} > {}\".format(codon, mutation))\n",
    "        \n",
    "        # Amplification primers for whole cds into\n",
    "        # BamHI cut Nt FHH pLEX uORF.\n",
    "        pm = primerMaker(blocks=[str(cds_dna)], left=left_overlap, right=right_overlap)\n",
    "        pm.pick_primers()\n",
    "        \n",
    "        with open('fasta/{}.fa'.format(gene_name), 'w') as f:\n",
    "            f.write(pm.get_seq_as_fasta())\n",
    "            \n",
    "        lines = pm.one_per_line()\n",
    "        \n",
    "        lines = '\\n'.join([x for x in lines.split('\\n') if 'stit' in x])\n",
    "        bc_acc = re.sub('BC0', '', seq_record.id)\n",
    "        lines = re.sub('_0_', '', lines)\n",
    "        lines = re.sub('leftstitch', 'L_{}'.format(gene_name), lines)\n",
    "        lines = re.sub('rightstitch', 'R_{}'.format(gene_name), lines)\n",
    "        #print(pm.__dict__)\n",
    "        \n",
    "        # SDM primers for amplification in two parts for\n",
    "        # Infusion stitching.\n",
    "        mut_cds_dna = cds_dna[:snp_left] + mutation + cds_dna[snp_right:]\n",
    "\n",
    "        pm = primerMaker(blocks=[\n",
    "            str(mut_cds_dna[:snp_left]), str(mut_cds_dna[snp_left:])],\n",
    "            left=left_overlap, right=right_overlap)\n",
    "        \n",
    "        pm.pick_primers()\n",
    "        \n",
    "        with open('fasta/{}_{}.fa'.format(gene_name, str(aa_n) + aa_mut), 'w') as f:\n",
    "            f.write(pm.get_seq_as_fasta())\n",
    "            \n",
    "        lines_sdm = pm.one_per_line().split('\\n')\n",
    "        lines_sdm = '\\n'.join([x for x in lines_sdm if 'stitch' in x])\n",
    "        lines_sdm = re.sub('_0', '{}_0'.format(str(aa_n) + aa_mut), lines_sdm)\n",
    "        lines_sdm = re.sub('_1', '{}_1'.format(str(aa_n) + aa_mut), lines_sdm)\n",
    "        lines_sdm = re.sub('_leftstitch', 'L_{}'.format(gene_name), lines_sdm)\n",
    "        lines_sdm = re.sub('_rightstitch', 'R_{}'.format(gene_name), lines_sdm)\n",
    "        \n",
    "        #print(lines_sdm)\n",
    "        return lines + '\\n' + lines_sdm + '\\n'\n",
    "    \n",
    "import glob, re\n",
    "def parse_mutation(_str, return_no_mutation=False):\n",
    "    a = re.split('(\\d+)', _str)\n",
    "    if return_no_mutation:\n",
    "        return a[0], int(a[1]), a[0]\n",
    "    return a[0], int(a[1]), a[2]\n",
    "\n",
    "order = ''\n",
    "genbank_files = glob.glob('gb/*.gb') + glob.glob('gb/*.gbk')\n",
    "\n",
    "df = load_rbps()\n",
    "def get_fname(gene_name):\n",
    "    \n",
    "    if type(gene_name) != type(''):\n",
    "        return False\n",
    "    \n",
    "    matching_gbs = [x for x in genbank_files if gene_name in str(x)]\n",
    "\n",
    "    if len(matching_gbs):\n",
    "        fname = matching_gbs[0]\n",
    "    else:\n",
    "        fname = 'gb/{}.gb'.format(df.iloc[n]['URL'])\n",
    "        \n",
    "    if not os.path.exists(fname):\n",
    "        print(\"No file {}\".format(fname))\n",
    "        return False\n",
    "    \n",
    "    return fname\n",
    "\n",
    "# Read all CDSes from genbank files and write to a single fasta\n",
    "# in case this is handy later for BLASTing against expected \n",
    "# constructs.\n",
    "all_cds = ''\n",
    "cds = {}\n",
    "for n in range(df.shape[0]):\n",
    "    \n",
    "    gene_name = df.iloc[n]['Gene']\n",
    "    fname = get_fname(gene_name)\n",
    "\n",
    "    if fname:\n",
    "        for seq_record in SeqIO.parse(fname, \"genbank\"):\n",
    "            cds_dna, cds_aa, starts_with = get_cds_from_genbank_record(seq_record)\n",
    "            all_cds += f\">{gene_name}_{seq_record.id}_{fname}\\n\"\n",
    "            all_cds += f\"{cds_aa}\\n\"\n",
    "            cds[gene_name] = cds_aa\n",
    "            \n",
    "with open('outputs/all_expected_cds_from_genbank_input_files.fa', 'w') as f:\n",
    "    f.write(all_cds)\n",
    "    \n",
    "print('Exported all CDSes from genbank files.')\n",
    "\n",
    "# Clear the file outputs/pcr_product_sizes.txt that is used\n",
    "# for checking PCR lengths and mutations by hand.\n",
    "if os.path.exists('outputs/pcr_product_sizes.txt'):\n",
    "    os.system('rm outputs/pcr_product_sizes.txt')\n",
    "\n",
    "# Get primers for each mutation.\n",
    "for n in range(df.shape[0]):\n",
    "    print('---=---' * 7)\n",
    "    \n",
    "    gene_name = df.iloc[n]['Gene']\n",
    "    \n",
    "    fname = get_fname(gene_name)\n",
    "\n",
    "    print(gene_name, fname)\n",
    "    \n",
    "    if fname:\n",
    "        mut = parse_mutation(\n",
    "            df.iloc[n]['Mutation'])#, return_no_mutation=1)\n",
    "        #if gene_name in cds:\n",
    "        #    midpoint = int(len(cds[gene_name])/2)\n",
    "        #    mut = cds[gene_name][midpoint], midpoint + 1, cds[gene_name][midpoint]\n",
    "        #else:\n",
    "        #    print(f\"No CDS {gene_name}\")\n",
    "        lines = get_primers(fname, *mut, gene_name=df.iloc[n]['Gene'])\n",
    "        if lines:\n",
    "            order += lines\n",
    "\n",
    "#Write a text order sheet.\n",
    "#Well Position\tName\tSequence\n",
    "#A1\ttest1\tagagagaagagagagag\n",
    "with open('order.txt', 'w') as f:\n",
    "    f.write(order)\n",
    "\n",
    "# Write excel order sheet.\n",
    "rows = []\n",
    "alphabet = 'ABCDEFGHIJKLMNOPQRST'\n",
    "letter_index = 0\n",
    "number_index = 1\n",
    "for li in order.split('\\n'):\n",
    "    \n",
    "    # For now, skip the odd man out.\n",
    "    #if 'RARS2' in li:\n",
    "    #    continue\n",
    "    #if li.count('_') < 2:\n",
    "    #    continue\n",
    "    if 'RARS2' in li or ('_0L_' not in li and '_1R_' not in li):\n",
    "        if len(li.split('\\t')) < 2:\n",
    "            continue\n",
    "        \n",
    "        rows.append({\n",
    "            'Well Position': alphabet[letter_index]+str(number_index),\n",
    "            'Name': li.split('\\t')[0],\n",
    "            'Sequence': li.split('\\t')[1].rstrip('\\n'),\n",
    "            'Gene name': li.split('\\t')[0].split('_')[-1],\n",
    "        })\n",
    "        \n",
    "        if number_index >= 8:\n",
    "            letter_index += 1\n",
    "            number_index = 1\n",
    "        else:\n",
    "            number_index += 1\n",
    "        if letter_index > 7:\n",
    "            letter_index = 0\n",
    "            number_index = 1\n",
    "            \n",
    "order_df = pandas.DataFrame(rows)\n",
    "order_df.to_excel('order.xlsx', )\n",
    "\n",
    "print(order_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_rbps_do_we_have():\n",
    "    all_rbps = set()\n",
    "    all_mutations = {}\n",
    "    for fname in ['./primerPlates//plate1 IDT primer order 053119 RBP missense mutations TCGA all cancer.xlsx',\n",
    "                 './primerPlates/plate2 IDT primer order 053119 RBP missense mutations TCGA all cancer.xlsx',\n",
    "                 './primerPlates/Plate 3 IDT order.xlsx']:\n",
    "        df = pandas.read_excel(fname)\n",
    "        genes = pandas.read_excel(fname)['Gene name'].tolist()\n",
    "        genes = set([x for x in genes if type(x) == type('')])\n",
    "        count = {rbp:len(df.loc[df['Gene name']==rbp].index) for rbp in genes}\n",
    "        count = {rbp:(x-2)/2 for rbp, x in count.items()}\n",
    "        all_mutations.update(count)\n",
    "        print(count)\n",
    "        print(genes)\n",
    "        print(\"{}: {} cDNAs\".format(fname, len(genes)))\n",
    "        all_rbps |= genes\n",
    "    print(\"Total RBPs: {}\\n{}\".format(len(all_rbps), all_rbps))\n",
    "    total_mutations = sum(all_mutations.values())\n",
    "    print(\"Total mutations: {}\\n{}\".format(total_mutations, all_mutations))\n",
    "    total_new_clip_datasets = \\\n",
    "        len(all_rbps) * 2 + ( # WT replicates\n",
    "        total_mutations - len(all_rbps)) * 2  # Mutant replicates\n",
    "    \n",
    "    print(\"Number of CLIP datasets if 2 replicates/RBP: {}\".format(total_new_clip_datasets))\n",
    "    print(\"...Added to current datasets (+50) = {}\".format(50 + total_new_clip_datasets))\n",
    "how_many_rbps_do_we_have()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'AA AAA AAA AAA AAA AAA AAA AAA A'\n",
    "a.count('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfExps = glob.glob('/Users/dfporter/pma/dataAndScripts/clip/experiments/*/*xlsx')\n",
    "for fname in listOfExps:\n",
    "    try:\n",
    "        xl = pandas.ExcelFile(fname)\n",
    "        bca = [x for x in xl.sheet_names if re.search('bca', x, re.IGNORECASE)]\n",
    "    except:\n",
    "        #print(f\"Error reading {fname}\")\n",
    "        continue\n",
    "\n",
    "    for sheet in bca:\n",
    "        df = xl.parse(sheet)\n",
    "        asStr = df.to_csv( path_or_buf=None)\n",
    "        for li in asStr.split('\\n'):\n",
    "            if re.search('HCT116', li, re.IGNORECASE):\n",
    "                if '60' in li:\n",
    "                    print(fname, '\\n', li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_str = \"\"\"190703_elim_internal_cds_sequencing_of_minipreps_rbp_missense\t\t\t\n",
    "1\t\"6/23 NpL uORF DICER1 A3\"\tDICER1_aa200F\t\n",
    "2\t\"6/23 NpL uORF DICER1 A3\"\tDICER1_aa375F\t\n",
    "3\t\"6/23 NpL uORF DICER1 A3\"\tDICER1_aa600F\t\n",
    "4\t\"6/23 NpL uORF DICER1 A3\"\tDICER1_aa800F\t\n",
    "5\t\"6/23 NpL uORF DICER1 A3\"\tDICER1_aa1000F\t\n",
    "6\t\"6/23 NpL uORF DICER1 A3\"\tDICER1_aa1200F\t\n",
    "7\t\"6/23 NpL uORF DICER1 A3\"\tDICER1_aa1400F\t\n",
    "8\t\"6/23 NpL uORF DICER1 A3\"\tDICER1_aa1600F\t\n",
    "9\t\"7/2 DICER R944Q T2-9 NpL\"\tDICER1_aa200F\t\n",
    "10\t\"7/2 DICER R944Q T2-9 NpL\"\tDICER1_aa375F\t\n",
    "11\t\"7/2 DICER R944Q T2-9 NpL\"\tDICER1_aa600F\t\n",
    "12\t\"7/2 DICER R944Q T2-9 NpL\"\tDICER1_aa800F\t\n",
    "13\t\"7/2 DICER R944Q T2-9 NpL\"\tDICER1_aa1000F\t\n",
    "14\t\"7/2 DICER R944Q T2-9 NpL\"\tDICER1_aa1200F\t\n",
    "15\t\"7/2 DICER R944Q T2-9 NpL\"\tDICER1_aa1400F\t\n",
    "16\t\"7/2 DICER R944Q T2-9 NpL\"\tDICER1_aa1600F\t\n",
    "17\t\"7/2 RBM11 R74C T3-1 NpL\"\tDICER1_aa200F\t\n",
    "18\t\"7/2 RBM11 R74C T3-1 NpL\"\tDICER1_aa375F\t\n",
    "19\t\"7/2 RBM11 R74C T3-1 NpL\"\tDICER1_aa600F\t\n",
    "20\t\"7/2 RBM11 R74C T3-1 NpL\"\tDICER1_aa800F\t\n",
    "21\t\"7/2 RBM11 R74C T3-1 NpL\"\tDICER1_aa1000F\t\n",
    "22\t\"7/2 RBM11 R74C T3-1 NpL\"\tDICER1_aa1200F\t\n",
    "23\t\"7/2 RBM11 R74C T3-1 NpL\"\tDICER1_aa1400F\t\n",
    "24\t\"7/2 RBM11 R74C T3-1 NpL\"\tDICER1_aa1600F\t\n",
    "25\tB5 A1CF\tA1CF_aa200F\t\n",
    "26\tB5 A1CF\tA1CF_aa500R\t\n",
    "27\t\"7/2 mini KPNB1 552F T1-1 NpL\"\tKPNB1_aa200F\t\n",
    "28\t\"7/2 mini KPNB1 552F T1-1 NpL\"\tKPNB1_aa400F\t\n",
    "29\t\"7/2 mini KPNB1 552F T1-1 NpL\"\tKPNB1_aa850R\t\n",
    "30\t\"KPNB1 6/26 NpL uORF\"\tKPNB1_aa200F\t\n",
    "31\t\"KPNB1 6/26 NpL uORF\"\tKPNB1_aa400F\t\n",
    "32\t\"KPNB1 6/26 NpL uORF\"\tKPNB1_aa850R\t\n",
    "33\t\"DDX50 6/26 NpL ini 1 uORF\"\tDDX50_aa200F\t\n",
    "34\t\"DDX50 6/26 NpL ini 1 uORF\"\tDDX50_aa400F\t\n",
    "35\tDDX3X 528C E6\tDDX3X_aa200F\t\n",
    "36\tDDX3X 528C E6\tDDX3X_aa400F\t\n",
    "37\tDDX3X 528C E11\tDDX3X_aa200F\t\n",
    "38\tDDX3X 528C E11\tDDX3X_aa400F\t\n",
    "39\t\"7/2 DICER R944Q T2-9 NpL\"\tpTRE5\t\n",
    "40\t\"7/2 RBM11 R74C T3-1 NpL\"\tpTRE5\t\n",
    "41\t\"7/2 Rbfox1 69T T3-6 NpL\"\tpTRE5\t\n",
    "42\t\"72 A1CF E34K T4-3 NpL\"\tpTRE5\t\"\"\"\n",
    "#a = pandas.read_clipboard(sep='\\t')\n",
    "#print(a)\n",
    "#df = a\n",
    "df.columns = ['rxn',\n",
    "             'name', 'primer', 'NA']\n",
    "print(df.head())\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "def reformat_sanger(fasta_fname, _df):\n",
    "    df = _df.copy()\n",
    "    records = []\n",
    "    for seq_record in SeqIO.parse(fasta_fname, \"fasta\"):\n",
    "\n",
    "        num = int(seq_record.id.split('-')[-1].split('_')[0]) - 1\n",
    "#        print(df.loc[int(num), 'name'])\n",
    "        new_id = df.loc[num, 'name'] + ', ' + df.loc[num, 'primer'] + ', ' + seq_record.id\n",
    "\n",
    "        seq_record.id = re.sub(' ', '_', new_id)\n",
    "        records.append(SeqRecord(seq_record.seq, id=seq_record.id))\n",
    "        name = re.sub(',', '_', seq_record.id)\n",
    "        name = re.sub('/', '', name)\n",
    "        SeqIO.write(seq_record, os.path.dirname(fasta_fname) + f'/edited_names/{name}.fa', 'fasta') \n",
    "\n",
    "    SeqIO.write(records, os.path.dirname(fasta_fname) + '/all_edited_names.fa',\n",
    "               'fasta')\n",
    "reformat_sanger(\n",
    "    '/Users/dfporter/Desktop/sanger/seqs/190703_elim_miniprep_sequencing_internal_cds_primers/all.fa',\n",
    "    df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/Users/dfporter/Downloads/HWUDSRJE114-Alignment.txt'\n",
    "\n",
    "outli = ''\n",
    "in_aligns = False\n",
    "with open(fname) as f:\n",
    "    for li in f:\n",
    "        if in_aligns and re.search('\\AQuery= ', li):\n",
    "            in_aligns = False\n",
    "        elif in_aligns:\n",
    "            continue\n",
    "        elif re.search('\\AALIGNMENTS', li):\n",
    "            in_aligns = True\n",
    "            continue\n",
    "\n",
    "        outli += li\n",
    "\n",
    "with open(os.path.dirname(fname) + '/edited.txt', 'w') as f:\n",
    "    f.write(outli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len('dyeeedeeeeSLMWRAPKEEADYEDDF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "def how_many_rbps_are_verified(fname):\n",
    "    df = pandas.read_excel(fname, sheet_name='By protein')\n",
    "    results = collections.defaultdict(set)\n",
    "\n",
    "    for row in df.to_dict('records'):\n",
    "        \n",
    "        construct = str(row['Unnamed: 1'])\n",
    "        if construct in ['nan', '<-']:\n",
    "            continue\n",
    "            \n",
    "        verif = any([re.search('Verif', str(x), re.IGNORECASE) for x in row.values()])\n",
    "        if verif:\n",
    "            results['Have constructs'].add(construct)\n",
    "            results['Have RBPs'].add(construct.split(' ')[0])\n",
    "        else:\n",
    "            results['Missing RBPs'].add(construct.split(' ')[0])\n",
    "        \n",
    "        results['Missing RBPs'] -= results['Have RBPs']\n",
    "        \n",
    "        n_constructs = {\n",
    "            name: len([x for x in results['Have constructs'] if name in x]) for name in results['Have RBPs']}\n",
    "        results['at_least_two'] = set([\n",
    "            x for x, v in n_constructs.items() if v>1])\n",
    "        results['only_one_construct'] = set([\n",
    "            x for x, v in n_constructs.items() if v<=1])\n",
    "    for k, v in results.items():\n",
    "        print(f'{k}: {len(v)}')    \n",
    "    pp.pprint(results)\n",
    "    \n",
    "how_many_rbps_are_verified('./Sequencing_schemes_and_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
